{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 9258,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0032404406999351912,
      "grad_norm": 1.0984808206558228,
      "learning_rate": 7.194244604316547e-07,
      "loss": 0.9569,
      "step": 10
    },
    {
      "epoch": 0.0064808813998703824,
      "grad_norm": 1.1354241371154785,
      "learning_rate": 1.4388489208633094e-06,
      "loss": 0.961,
      "step": 20
    },
    {
      "epoch": 0.009721322099805573,
      "grad_norm": 1.1671613454818726,
      "learning_rate": 2.158273381294964e-06,
      "loss": 0.9435,
      "step": 30
    },
    {
      "epoch": 0.012961762799740765,
      "grad_norm": 1.2857704162597656,
      "learning_rate": 2.877697841726619e-06,
      "loss": 0.956,
      "step": 40
    },
    {
      "epoch": 0.016202203499675955,
      "grad_norm": 1.3086421489715576,
      "learning_rate": 3.5971223021582737e-06,
      "loss": 0.9152,
      "step": 50
    },
    {
      "epoch": 0.019442644199611146,
      "grad_norm": 1.1429575681686401,
      "learning_rate": 4.316546762589928e-06,
      "loss": 0.8526,
      "step": 60
    },
    {
      "epoch": 0.02268308489954634,
      "grad_norm": 1.0251281261444092,
      "learning_rate": 5.035971223021583e-06,
      "loss": 0.791,
      "step": 70
    },
    {
      "epoch": 0.02592352559948153,
      "grad_norm": 0.5967735052108765,
      "learning_rate": 5.755395683453238e-06,
      "loss": 0.6644,
      "step": 80
    },
    {
      "epoch": 0.02916396629941672,
      "grad_norm": 0.629619300365448,
      "learning_rate": 6.474820143884892e-06,
      "loss": 0.5914,
      "step": 90
    },
    {
      "epoch": 0.03240440699935191,
      "grad_norm": 0.45594093203544617,
      "learning_rate": 7.194244604316547e-06,
      "loss": 0.5126,
      "step": 100
    },
    {
      "epoch": 0.0356448476992871,
      "grad_norm": 0.4102739095687866,
      "learning_rate": 7.913669064748202e-06,
      "loss": 0.4641,
      "step": 110
    },
    {
      "epoch": 0.03888528839922229,
      "grad_norm": 0.32244473695755005,
      "learning_rate": 8.633093525179856e-06,
      "loss": 0.4274,
      "step": 120
    },
    {
      "epoch": 0.04212572909915749,
      "grad_norm": 0.32552260160446167,
      "learning_rate": 9.35251798561151e-06,
      "loss": 0.4015,
      "step": 130
    },
    {
      "epoch": 0.04536616979909268,
      "grad_norm": 0.29631078243255615,
      "learning_rate": 1.0071942446043167e-05,
      "loss": 0.3797,
      "step": 140
    },
    {
      "epoch": 0.04860661049902787,
      "grad_norm": 0.27749350666999817,
      "learning_rate": 1.0791366906474821e-05,
      "loss": 0.3632,
      "step": 150
    },
    {
      "epoch": 0.05184705119896306,
      "grad_norm": 0.2610642910003662,
      "learning_rate": 1.1510791366906475e-05,
      "loss": 0.3434,
      "step": 160
    },
    {
      "epoch": 0.05508749189889825,
      "grad_norm": 0.2628144323825836,
      "learning_rate": 1.223021582733813e-05,
      "loss": 0.3367,
      "step": 170
    },
    {
      "epoch": 0.05832793259883344,
      "grad_norm": 0.26857268810272217,
      "learning_rate": 1.2949640287769784e-05,
      "loss": 0.3137,
      "step": 180
    },
    {
      "epoch": 0.06156837329876863,
      "grad_norm": 0.3184756636619568,
      "learning_rate": 1.3669064748201439e-05,
      "loss": 0.3106,
      "step": 190
    },
    {
      "epoch": 0.06480881399870382,
      "grad_norm": 0.26283708214759827,
      "learning_rate": 1.4388489208633095e-05,
      "loss": 0.3014,
      "step": 200
    },
    {
      "epoch": 0.06804925469863901,
      "grad_norm": 0.29916825890541077,
      "learning_rate": 1.5107913669064749e-05,
      "loss": 0.3057,
      "step": 210
    },
    {
      "epoch": 0.0712896953985742,
      "grad_norm": 0.27330631017684937,
      "learning_rate": 1.5827338129496403e-05,
      "loss": 0.2954,
      "step": 220
    },
    {
      "epoch": 0.07453013609850939,
      "grad_norm": 0.31961727142333984,
      "learning_rate": 1.6546762589928058e-05,
      "loss": 0.2863,
      "step": 230
    },
    {
      "epoch": 0.07777057679844458,
      "grad_norm": 0.2847130000591278,
      "learning_rate": 1.7266187050359712e-05,
      "loss": 0.2884,
      "step": 240
    },
    {
      "epoch": 0.08101101749837979,
      "grad_norm": 0.29844632744789124,
      "learning_rate": 1.7985611510791367e-05,
      "loss": 0.2804,
      "step": 250
    },
    {
      "epoch": 0.08425145819831498,
      "grad_norm": 0.3032001256942749,
      "learning_rate": 1.870503597122302e-05,
      "loss": 0.2737,
      "step": 260
    },
    {
      "epoch": 0.08749189889825017,
      "grad_norm": 0.3141809403896332,
      "learning_rate": 1.9424460431654675e-05,
      "loss": 0.2729,
      "step": 270
    },
    {
      "epoch": 0.09073233959818536,
      "grad_norm": 0.3075140416622162,
      "learning_rate": 1.9999997552193694e-05,
      "loss": 0.2702,
      "step": 280
    },
    {
      "epoch": 0.09397278029812055,
      "grad_norm": 0.32165399193763733,
      "learning_rate": 1.9999911879098665e-05,
      "loss": 0.2686,
      "step": 290
    },
    {
      "epoch": 0.09721322099805574,
      "grad_norm": 0.30995628237724304,
      "learning_rate": 1.999970381688648e-05,
      "loss": 0.2697,
      "step": 300
    },
    {
      "epoch": 0.10045366169799093,
      "grad_norm": 0.35066917538642883,
      "learning_rate": 1.9999373368103622e-05,
      "loss": 0.2609,
      "step": 310
    },
    {
      "epoch": 0.10369410239792612,
      "grad_norm": 0.31409794092178345,
      "learning_rate": 1.999892053679445e-05,
      "loss": 0.2556,
      "step": 320
    },
    {
      "epoch": 0.10693454309786131,
      "grad_norm": 0.3180046081542969,
      "learning_rate": 1.9998345328501177e-05,
      "loss": 0.2559,
      "step": 330
    },
    {
      "epoch": 0.1101749837977965,
      "grad_norm": 0.3175669312477112,
      "learning_rate": 1.9997647750263795e-05,
      "loss": 0.2545,
      "step": 340
    },
    {
      "epoch": 0.11341542449773169,
      "grad_norm": 0.30866122245788574,
      "learning_rate": 1.9996827810619972e-05,
      "loss": 0.254,
      "step": 350
    },
    {
      "epoch": 0.11665586519766688,
      "grad_norm": 0.3110976219177246,
      "learning_rate": 1.9995885519604967e-05,
      "loss": 0.2386,
      "step": 360
    },
    {
      "epoch": 0.11989630589760207,
      "grad_norm": 0.3262001574039459,
      "learning_rate": 1.99948208887515e-05,
      "loss": 0.2463,
      "step": 370
    },
    {
      "epoch": 0.12313674659753726,
      "grad_norm": 0.3157125413417816,
      "learning_rate": 1.9993633931089605e-05,
      "loss": 0.248,
      "step": 380
    },
    {
      "epoch": 0.12637718729747247,
      "grad_norm": 0.4133487939834595,
      "learning_rate": 1.9992324661146485e-05,
      "loss": 0.2488,
      "step": 390
    },
    {
      "epoch": 0.12961762799740764,
      "grad_norm": 0.31403106451034546,
      "learning_rate": 1.9990893094946315e-05,
      "loss": 0.2424,
      "step": 400
    },
    {
      "epoch": 0.13285806869734285,
      "grad_norm": 0.34352874755859375,
      "learning_rate": 1.9989339250010064e-05,
      "loss": 0.2354,
      "step": 410
    },
    {
      "epoch": 0.13609850939727802,
      "grad_norm": 0.37925124168395996,
      "learning_rate": 1.9987663145355272e-05,
      "loss": 0.2454,
      "step": 420
    },
    {
      "epoch": 0.13933895009721323,
      "grad_norm": 0.3785078823566437,
      "learning_rate": 1.9985864801495815e-05,
      "loss": 0.2416,
      "step": 430
    },
    {
      "epoch": 0.1425793907971484,
      "grad_norm": 0.36176830530166626,
      "learning_rate": 1.998394424044166e-05,
      "loss": 0.2349,
      "step": 440
    },
    {
      "epoch": 0.1458198314970836,
      "grad_norm": 0.42837631702423096,
      "learning_rate": 1.998190148569859e-05,
      "loss": 0.2435,
      "step": 450
    },
    {
      "epoch": 0.14906027219701878,
      "grad_norm": 0.4057552218437195,
      "learning_rate": 1.997973656226792e-05,
      "loss": 0.2354,
      "step": 460
    },
    {
      "epoch": 0.152300712896954,
      "grad_norm": 0.36729696393013,
      "learning_rate": 1.997744949664619e-05,
      "loss": 0.2356,
      "step": 470
    },
    {
      "epoch": 0.15554115359688916,
      "grad_norm": 0.3810172379016876,
      "learning_rate": 1.9975040316824848e-05,
      "loss": 0.234,
      "step": 480
    },
    {
      "epoch": 0.15878159429682437,
      "grad_norm": 0.3748362362384796,
      "learning_rate": 1.9972509052289882e-05,
      "loss": 0.2323,
      "step": 490
    },
    {
      "epoch": 0.16202203499675957,
      "grad_norm": 0.3420867919921875,
      "learning_rate": 1.9969855734021497e-05,
      "loss": 0.2278,
      "step": 500
    },
    {
      "epoch": 0.16526247569669475,
      "grad_norm": 0.37850290536880493,
      "learning_rate": 1.99670803944937e-05,
      "loss": 0.2272,
      "step": 510
    },
    {
      "epoch": 0.16850291639662995,
      "grad_norm": 0.35996878147125244,
      "learning_rate": 1.996418306767393e-05,
      "loss": 0.2315,
      "step": 520
    },
    {
      "epoch": 0.17174335709656513,
      "grad_norm": 0.3764866590499878,
      "learning_rate": 1.9961163789022625e-05,
      "loss": 0.2317,
      "step": 530
    },
    {
      "epoch": 0.17498379779650033,
      "grad_norm": 0.4204109013080597,
      "learning_rate": 1.9958022595492793e-05,
      "loss": 0.2277,
      "step": 540
    },
    {
      "epoch": 0.1782242384964355,
      "grad_norm": 0.3712562918663025,
      "learning_rate": 1.995475952552957e-05,
      "loss": 0.2249,
      "step": 550
    },
    {
      "epoch": 0.18146467919637072,
      "grad_norm": 0.43525430560112,
      "learning_rate": 1.995137461906973e-05,
      "loss": 0.2196,
      "step": 560
    },
    {
      "epoch": 0.1847051198963059,
      "grad_norm": 0.3601027727127075,
      "learning_rate": 1.994786791754121e-05,
      "loss": 0.231,
      "step": 570
    },
    {
      "epoch": 0.1879455605962411,
      "grad_norm": 0.3747655153274536,
      "learning_rate": 1.9944239463862596e-05,
      "loss": 0.2267,
      "step": 580
    },
    {
      "epoch": 0.19118600129617627,
      "grad_norm": 0.3927771747112274,
      "learning_rate": 1.9940489302442604e-05,
      "loss": 0.2194,
      "step": 590
    },
    {
      "epoch": 0.19442644199611148,
      "grad_norm": 0.3585400879383087,
      "learning_rate": 1.9936617479179533e-05,
      "loss": 0.2197,
      "step": 600
    },
    {
      "epoch": 0.19766688269604665,
      "grad_norm": 0.37684166431427,
      "learning_rate": 1.9932624041460706e-05,
      "loss": 0.2238,
      "step": 610
    },
    {
      "epoch": 0.20090732339598186,
      "grad_norm": 0.4065299928188324,
      "learning_rate": 1.9928509038161886e-05,
      "loss": 0.2164,
      "step": 620
    },
    {
      "epoch": 0.20414776409591703,
      "grad_norm": 0.3814970552921295,
      "learning_rate": 1.9924272519646675e-05,
      "loss": 0.2242,
      "step": 630
    },
    {
      "epoch": 0.20738820479585224,
      "grad_norm": 0.3939903974533081,
      "learning_rate": 1.9919914537765908e-05,
      "loss": 0.2224,
      "step": 640
    },
    {
      "epoch": 0.21062864549578741,
      "grad_norm": 0.37732410430908203,
      "learning_rate": 1.9915435145857008e-05,
      "loss": 0.22,
      "step": 650
    },
    {
      "epoch": 0.21386908619572262,
      "grad_norm": 0.3655115067958832,
      "learning_rate": 1.9910834398743347e-05,
      "loss": 0.217,
      "step": 660
    },
    {
      "epoch": 0.21710952689565782,
      "grad_norm": 0.37472161650657654,
      "learning_rate": 1.9906112352733554e-05,
      "loss": 0.2173,
      "step": 670
    },
    {
      "epoch": 0.220349967595593,
      "grad_norm": 0.3822198808193207,
      "learning_rate": 1.9901269065620842e-05,
      "loss": 0.2219,
      "step": 680
    },
    {
      "epoch": 0.2235904082955282,
      "grad_norm": 0.41184625029563904,
      "learning_rate": 1.98963045966823e-05,
      "loss": 0.218,
      "step": 690
    },
    {
      "epoch": 0.22683084899546338,
      "grad_norm": 0.40795090794563293,
      "learning_rate": 1.9891219006678156e-05,
      "loss": 0.2183,
      "step": 700
    },
    {
      "epoch": 0.23007128969539858,
      "grad_norm": 0.3888797461986542,
      "learning_rate": 1.988601235785105e-05,
      "loss": 0.2205,
      "step": 710
    },
    {
      "epoch": 0.23331173039533376,
      "grad_norm": 0.39574024081230164,
      "learning_rate": 1.9880684713925254e-05,
      "loss": 0.2213,
      "step": 720
    },
    {
      "epoch": 0.23655217109526896,
      "grad_norm": 0.39762040972709656,
      "learning_rate": 1.9875236140105908e-05,
      "loss": 0.2096,
      "step": 730
    },
    {
      "epoch": 0.23979261179520414,
      "grad_norm": 0.4018053412437439,
      "learning_rate": 1.986966670307822e-05,
      "loss": 0.21,
      "step": 740
    },
    {
      "epoch": 0.24303305249513935,
      "grad_norm": 0.40227940678596497,
      "learning_rate": 1.9863976471006632e-05,
      "loss": 0.2179,
      "step": 750
    },
    {
      "epoch": 0.24627349319507452,
      "grad_norm": 0.4103274345397949,
      "learning_rate": 1.9858165513534002e-05,
      "loss": 0.2219,
      "step": 760
    },
    {
      "epoch": 0.24951393389500973,
      "grad_norm": 0.46883660554885864,
      "learning_rate": 1.9852233901780762e-05,
      "loss": 0.2189,
      "step": 770
    },
    {
      "epoch": 0.25275437459494493,
      "grad_norm": 0.4321233332157135,
      "learning_rate": 1.9846181708344022e-05,
      "loss": 0.2118,
      "step": 780
    },
    {
      "epoch": 0.2559948152948801,
      "grad_norm": 0.4143153727054596,
      "learning_rate": 1.984000900729669e-05,
      "loss": 0.209,
      "step": 790
    },
    {
      "epoch": 0.2592352559948153,
      "grad_norm": 0.4467546343803406,
      "learning_rate": 1.9833715874186578e-05,
      "loss": 0.2184,
      "step": 800
    },
    {
      "epoch": 0.26247569669475046,
      "grad_norm": 0.4422396123409271,
      "learning_rate": 1.9827302386035467e-05,
      "loss": 0.2114,
      "step": 810
    },
    {
      "epoch": 0.2657161373946857,
      "grad_norm": 0.4154554605484009,
      "learning_rate": 1.9820768621338156e-05,
      "loss": 0.2107,
      "step": 820
    },
    {
      "epoch": 0.26895657809462087,
      "grad_norm": 0.3997843563556671,
      "learning_rate": 1.9814114660061533e-05,
      "loss": 0.2095,
      "step": 830
    },
    {
      "epoch": 0.27219701879455604,
      "grad_norm": 0.4599810838699341,
      "learning_rate": 1.980734058364355e-05,
      "loss": 0.2129,
      "step": 840
    },
    {
      "epoch": 0.2754374594944913,
      "grad_norm": 0.41847413778305054,
      "learning_rate": 1.980044647499227e-05,
      "loss": 0.2166,
      "step": 850
    },
    {
      "epoch": 0.27867790019442645,
      "grad_norm": 0.41835513710975647,
      "learning_rate": 1.979343241848481e-05,
      "loss": 0.2095,
      "step": 860
    },
    {
      "epoch": 0.28191834089436163,
      "grad_norm": 0.4021320641040802,
      "learning_rate": 1.9786298499966356e-05,
      "loss": 0.213,
      "step": 870
    },
    {
      "epoch": 0.2851587815942968,
      "grad_norm": 0.40832751989364624,
      "learning_rate": 1.9779044806749072e-05,
      "loss": 0.2117,
      "step": 880
    },
    {
      "epoch": 0.28839922229423204,
      "grad_norm": 0.3730926215648651,
      "learning_rate": 1.977167142761105e-05,
      "loss": 0.2175,
      "step": 890
    },
    {
      "epoch": 0.2916396629941672,
      "grad_norm": 0.41191890835762024,
      "learning_rate": 1.9764178452795227e-05,
      "loss": 0.205,
      "step": 900
    },
    {
      "epoch": 0.2948801036941024,
      "grad_norm": 0.4078294038772583,
      "learning_rate": 1.9756565974008262e-05,
      "loss": 0.2101,
      "step": 910
    },
    {
      "epoch": 0.29812054439403757,
      "grad_norm": 0.4264111816883087,
      "learning_rate": 1.9748834084419433e-05,
      "loss": 0.208,
      "step": 920
    },
    {
      "epoch": 0.3013609850939728,
      "grad_norm": 0.45361387729644775,
      "learning_rate": 1.974098287865949e-05,
      "loss": 0.2079,
      "step": 930
    },
    {
      "epoch": 0.304601425793908,
      "grad_norm": 0.4196248948574066,
      "learning_rate": 1.9733012452819496e-05,
      "loss": 0.2125,
      "step": 940
    },
    {
      "epoch": 0.30784186649384315,
      "grad_norm": 0.3983025550842285,
      "learning_rate": 1.9724922904449646e-05,
      "loss": 0.2123,
      "step": 950
    },
    {
      "epoch": 0.31108230719377833,
      "grad_norm": 0.42009618878364563,
      "learning_rate": 1.971671433255808e-05,
      "loss": 0.2083,
      "step": 960
    },
    {
      "epoch": 0.31432274789371356,
      "grad_norm": 0.47055676579475403,
      "learning_rate": 1.970838683760967e-05,
      "loss": 0.2079,
      "step": 970
    },
    {
      "epoch": 0.31756318859364874,
      "grad_norm": 0.4146258234977722,
      "learning_rate": 1.9699940521524793e-05,
      "loss": 0.2067,
      "step": 980
    },
    {
      "epoch": 0.3208036292935839,
      "grad_norm": 0.4181731343269348,
      "learning_rate": 1.969137548767807e-05,
      "loss": 0.2079,
      "step": 990
    },
    {
      "epoch": 0.32404406999351915,
      "grad_norm": 0.435835063457489,
      "learning_rate": 1.9682691840897128e-05,
      "loss": 0.2066,
      "step": 1000
    },
    {
      "epoch": 0.3272845106934543,
      "grad_norm": 0.42853257060050964,
      "learning_rate": 1.967388968746128e-05,
      "loss": 0.2061,
      "step": 1010
    },
    {
      "epoch": 0.3305249513933895,
      "grad_norm": 0.4257517457008362,
      "learning_rate": 1.9664969135100262e-05,
      "loss": 0.2045,
      "step": 1020
    },
    {
      "epoch": 0.3337653920933247,
      "grad_norm": 0.4433983266353607,
      "learning_rate": 1.9655930292992882e-05,
      "loss": 0.2039,
      "step": 1030
    },
    {
      "epoch": 0.3370058327932599,
      "grad_norm": 0.4563511312007904,
      "learning_rate": 1.9646773271765712e-05,
      "loss": 0.2067,
      "step": 1040
    },
    {
      "epoch": 0.3402462734931951,
      "grad_norm": 0.4051141142845154,
      "learning_rate": 1.9637498183491708e-05,
      "loss": 0.2046,
      "step": 1050
    },
    {
      "epoch": 0.34348671419313026,
      "grad_norm": 0.40741270780563354,
      "learning_rate": 1.962810514168886e-05,
      "loss": 0.2047,
      "step": 1060
    },
    {
      "epoch": 0.34672715489306544,
      "grad_norm": 0.4606398344039917,
      "learning_rate": 1.9618594261318788e-05,
      "loss": 0.2034,
      "step": 1070
    },
    {
      "epoch": 0.34996759559300067,
      "grad_norm": 0.416505366563797,
      "learning_rate": 1.960896565878535e-05,
      "loss": 0.2088,
      "step": 1080
    },
    {
      "epoch": 0.35320803629293585,
      "grad_norm": 0.45712965726852417,
      "learning_rate": 1.959921945193319e-05,
      "loss": 0.2052,
      "step": 1090
    },
    {
      "epoch": 0.356448476992871,
      "grad_norm": 0.40778306126594543,
      "learning_rate": 1.9589355760046332e-05,
      "loss": 0.2035,
      "step": 1100
    },
    {
      "epoch": 0.3596889176928062,
      "grad_norm": 0.43493643403053284,
      "learning_rate": 1.9579374703846693e-05,
      "loss": 0.2051,
      "step": 1110
    },
    {
      "epoch": 0.36292935839274143,
      "grad_norm": 0.43059825897216797,
      "learning_rate": 1.9569276405492616e-05,
      "loss": 0.2082,
      "step": 1120
    },
    {
      "epoch": 0.3661697990926766,
      "grad_norm": 0.4603644013404846,
      "learning_rate": 1.9559060988577365e-05,
      "loss": 0.2059,
      "step": 1130
    },
    {
      "epoch": 0.3694102397926118,
      "grad_norm": 0.5044971704483032,
      "learning_rate": 1.9548728578127635e-05,
      "loss": 0.2045,
      "step": 1140
    },
    {
      "epoch": 0.37265068049254696,
      "grad_norm": 0.39440804719924927,
      "learning_rate": 1.9538279300602e-05,
      "loss": 0.2067,
      "step": 1150
    },
    {
      "epoch": 0.3758911211924822,
      "grad_norm": 0.42207881808280945,
      "learning_rate": 1.952771328388937e-05,
      "loss": 0.2057,
      "step": 1160
    },
    {
      "epoch": 0.37913156189241737,
      "grad_norm": 0.476853609085083,
      "learning_rate": 1.9517030657307425e-05,
      "loss": 0.2069,
      "step": 1170
    },
    {
      "epoch": 0.38237200259235254,
      "grad_norm": 0.4515531063079834,
      "learning_rate": 1.950623155160105e-05,
      "loss": 0.1961,
      "step": 1180
    },
    {
      "epoch": 0.3856124432922878,
      "grad_norm": 0.4468933045864105,
      "learning_rate": 1.9495316098940706e-05,
      "loss": 0.1991,
      "step": 1190
    },
    {
      "epoch": 0.38885288399222295,
      "grad_norm": 0.4299362301826477,
      "learning_rate": 1.9484284432920832e-05,
      "loss": 0.2002,
      "step": 1200
    },
    {
      "epoch": 0.39209332469215813,
      "grad_norm": 0.4672532379627228,
      "learning_rate": 1.9473136688558202e-05,
      "loss": 0.202,
      "step": 1210
    },
    {
      "epoch": 0.3953337653920933,
      "grad_norm": 0.4147225618362427,
      "learning_rate": 1.9461873002290282e-05,
      "loss": 0.2021,
      "step": 1220
    },
    {
      "epoch": 0.39857420609202854,
      "grad_norm": 0.48085007071495056,
      "learning_rate": 1.9450493511973548e-05,
      "loss": 0.2015,
      "step": 1230
    },
    {
      "epoch": 0.4018146467919637,
      "grad_norm": 0.44306761026382446,
      "learning_rate": 1.94389983568818e-05,
      "loss": 0.198,
      "step": 1240
    },
    {
      "epoch": 0.4050550874918989,
      "grad_norm": 0.4174209535121918,
      "learning_rate": 1.9427387677704472e-05,
      "loss": 0.2023,
      "step": 1250
    },
    {
      "epoch": 0.40829552819183407,
      "grad_norm": 0.4595993459224701,
      "learning_rate": 1.9415661616544892e-05,
      "loss": 0.2002,
      "step": 1260
    },
    {
      "epoch": 0.4115359688917693,
      "grad_norm": 0.5132812261581421,
      "learning_rate": 1.940382031691855e-05,
      "loss": 0.1983,
      "step": 1270
    },
    {
      "epoch": 0.4147764095917045,
      "grad_norm": 0.4652480185031891,
      "learning_rate": 1.9391863923751346e-05,
      "loss": 0.1987,
      "step": 1280
    },
    {
      "epoch": 0.41801685029163965,
      "grad_norm": 0.4522657096385956,
      "learning_rate": 1.9379792583377807e-05,
      "loss": 0.1994,
      "step": 1290
    },
    {
      "epoch": 0.42125729099157483,
      "grad_norm": 0.43978214263916016,
      "learning_rate": 1.9367606443539303e-05,
      "loss": 0.2047,
      "step": 1300
    },
    {
      "epoch": 0.42449773169151006,
      "grad_norm": 0.4243377149105072,
      "learning_rate": 1.9355305653382243e-05,
      "loss": 0.1996,
      "step": 1310
    },
    {
      "epoch": 0.42773817239144524,
      "grad_norm": 0.44610047340393066,
      "learning_rate": 1.934289036345624e-05,
      "loss": 0.199,
      "step": 1320
    },
    {
      "epoch": 0.4309786130913804,
      "grad_norm": 0.5571054816246033,
      "learning_rate": 1.9330360725712263e-05,
      "loss": 0.2038,
      "step": 1330
    },
    {
      "epoch": 0.43421905379131565,
      "grad_norm": 0.49094894528388977,
      "learning_rate": 1.93177168935008e-05,
      "loss": 0.1986,
      "step": 1340
    },
    {
      "epoch": 0.4374594944912508,
      "grad_norm": 0.45873722434043884,
      "learning_rate": 1.930495902156995e-05,
      "loss": 0.1979,
      "step": 1350
    },
    {
      "epoch": 0.440699935191186,
      "grad_norm": 0.41223078966140747,
      "learning_rate": 1.929208726606357e-05,
      "loss": 0.1949,
      "step": 1360
    },
    {
      "epoch": 0.4439403758911212,
      "grad_norm": 0.4191155433654785,
      "learning_rate": 1.9279101784519326e-05,
      "loss": 0.1962,
      "step": 1370
    },
    {
      "epoch": 0.4471808165910564,
      "grad_norm": 0.4587065279483795,
      "learning_rate": 1.9266002735866775e-05,
      "loss": 0.1967,
      "step": 1380
    },
    {
      "epoch": 0.4504212572909916,
      "grad_norm": 0.4302157461643219,
      "learning_rate": 1.9252790280425428e-05,
      "loss": 0.2004,
      "step": 1390
    },
    {
      "epoch": 0.45366169799092676,
      "grad_norm": 0.49794262647628784,
      "learning_rate": 1.9239464579902797e-05,
      "loss": 0.1978,
      "step": 1400
    },
    {
      "epoch": 0.45690213869086194,
      "grad_norm": 0.46508878469467163,
      "learning_rate": 1.9226025797392375e-05,
      "loss": 0.198,
      "step": 1410
    },
    {
      "epoch": 0.46014257939079717,
      "grad_norm": 0.43777140974998474,
      "learning_rate": 1.92124740973717e-05,
      "loss": 0.1979,
      "step": 1420
    },
    {
      "epoch": 0.46338302009073234,
      "grad_norm": 0.4213823080062866,
      "learning_rate": 1.9198809645700285e-05,
      "loss": 0.1987,
      "step": 1430
    },
    {
      "epoch": 0.4666234607906675,
      "grad_norm": 0.4479846954345703,
      "learning_rate": 1.9185032609617623e-05,
      "loss": 0.2016,
      "step": 1440
    },
    {
      "epoch": 0.4698639014906027,
      "grad_norm": 0.47768649458885193,
      "learning_rate": 1.917114315774113e-05,
      "loss": 0.2001,
      "step": 1450
    },
    {
      "epoch": 0.47310434219053793,
      "grad_norm": 0.459078311920166,
      "learning_rate": 1.9157141460064077e-05,
      "loss": 0.2006,
      "step": 1460
    },
    {
      "epoch": 0.4763447828904731,
      "grad_norm": 0.4958800971508026,
      "learning_rate": 1.9143027687953516e-05,
      "loss": 0.2003,
      "step": 1470
    },
    {
      "epoch": 0.4795852235904083,
      "grad_norm": 0.4723593592643738,
      "learning_rate": 1.9128802014148182e-05,
      "loss": 0.1985,
      "step": 1480
    },
    {
      "epoch": 0.48282566429034346,
      "grad_norm": 0.4542725086212158,
      "learning_rate": 1.9114464612756373e-05,
      "loss": 0.198,
      "step": 1490
    },
    {
      "epoch": 0.4860661049902787,
      "grad_norm": 0.44925951957702637,
      "learning_rate": 1.9100015659253825e-05,
      "loss": 0.1915,
      "step": 1500
    },
    {
      "epoch": 0.48930654569021387,
      "grad_norm": 0.4533328413963318,
      "learning_rate": 1.9085455330481565e-05,
      "loss": 0.1964,
      "step": 1510
    },
    {
      "epoch": 0.49254698639014904,
      "grad_norm": 0.4760035574436188,
      "learning_rate": 1.9070783804643736e-05,
      "loss": 0.1961,
      "step": 1520
    },
    {
      "epoch": 0.4957874270900843,
      "grad_norm": 0.5241211652755737,
      "learning_rate": 1.905600126130544e-05,
      "loss": 0.2057,
      "step": 1530
    },
    {
      "epoch": 0.49902786779001945,
      "grad_norm": 0.503784716129303,
      "learning_rate": 1.9041107881390507e-05,
      "loss": 0.1963,
      "step": 1540
    },
    {
      "epoch": 0.5022683084899546,
      "grad_norm": 0.4376278519630432,
      "learning_rate": 1.9026103847179303e-05,
      "loss": 0.1925,
      "step": 1550
    },
    {
      "epoch": 0.5055087491898899,
      "grad_norm": 0.48728618025779724,
      "learning_rate": 1.9010989342306503e-05,
      "loss": 0.192,
      "step": 1560
    },
    {
      "epoch": 0.508749189889825,
      "grad_norm": 0.4559136629104614,
      "learning_rate": 1.8995764551758824e-05,
      "loss": 0.1991,
      "step": 1570
    },
    {
      "epoch": 0.5119896305897602,
      "grad_norm": 0.4470703899860382,
      "learning_rate": 1.8980429661872776e-05,
      "loss": 0.1925,
      "step": 1580
    },
    {
      "epoch": 0.5152300712896954,
      "grad_norm": 0.44985443353652954,
      "learning_rate": 1.8964984860332376e-05,
      "loss": 0.1906,
      "step": 1590
    },
    {
      "epoch": 0.5184705119896306,
      "grad_norm": 0.4872954189777374,
      "learning_rate": 1.8949430336166852e-05,
      "loss": 0.1959,
      "step": 1600
    },
    {
      "epoch": 0.5217109526895658,
      "grad_norm": 0.5040152072906494,
      "learning_rate": 1.893376627974833e-05,
      "loss": 0.1948,
      "step": 1610
    },
    {
      "epoch": 0.5249513933895009,
      "grad_norm": 0.44267427921295166,
      "learning_rate": 1.8917992882789507e-05,
      "loss": 0.1909,
      "step": 1620
    },
    {
      "epoch": 0.5281918340894362,
      "grad_norm": 0.4394974410533905,
      "learning_rate": 1.8902110338341287e-05,
      "loss": 0.197,
      "step": 1630
    },
    {
      "epoch": 0.5314322747893714,
      "grad_norm": 0.4817621111869812,
      "learning_rate": 1.8886118840790458e-05,
      "loss": 0.1927,
      "step": 1640
    },
    {
      "epoch": 0.5346727154893065,
      "grad_norm": 0.4844663441181183,
      "learning_rate": 1.8870018585857256e-05,
      "loss": 0.194,
      "step": 1650
    },
    {
      "epoch": 0.5379131561892417,
      "grad_norm": 0.43174538016319275,
      "learning_rate": 1.885380977059302e-05,
      "loss": 0.193,
      "step": 1660
    },
    {
      "epoch": 0.541153596889177,
      "grad_norm": 0.4473322629928589,
      "learning_rate": 1.8837492593377762e-05,
      "loss": 0.1908,
      "step": 1670
    },
    {
      "epoch": 0.5443940375891121,
      "grad_norm": 0.4557097852230072,
      "learning_rate": 1.8821067253917735e-05,
      "loss": 0.1952,
      "step": 1680
    },
    {
      "epoch": 0.5476344782890473,
      "grad_norm": 0.4812805652618408,
      "learning_rate": 1.8804533953242977e-05,
      "loss": 0.1942,
      "step": 1690
    },
    {
      "epoch": 0.5508749189889826,
      "grad_norm": 0.5172750949859619,
      "learning_rate": 1.8787892893704895e-05,
      "loss": 0.1962,
      "step": 1700
    },
    {
      "epoch": 0.5541153596889177,
      "grad_norm": 0.46973249316215515,
      "learning_rate": 1.8771144278973728e-05,
      "loss": 0.1905,
      "step": 1710
    },
    {
      "epoch": 0.5573558003888529,
      "grad_norm": 0.45115384459495544,
      "learning_rate": 1.8754288314036108e-05,
      "loss": 0.1917,
      "step": 1720
    },
    {
      "epoch": 0.560596241088788,
      "grad_norm": 0.4768901467323303,
      "learning_rate": 1.8737325205192518e-05,
      "loss": 0.1893,
      "step": 1730
    },
    {
      "epoch": 0.5638366817887233,
      "grad_norm": 0.4288588762283325,
      "learning_rate": 1.8720255160054778e-05,
      "loss": 0.1877,
      "step": 1740
    },
    {
      "epoch": 0.5670771224886585,
      "grad_norm": 0.48053812980651855,
      "learning_rate": 1.8703078387543506e-05,
      "loss": 0.1926,
      "step": 1750
    },
    {
      "epoch": 0.5703175631885936,
      "grad_norm": 0.480272114276886,
      "learning_rate": 1.8685795097885556e-05,
      "loss": 0.1961,
      "step": 1760
    },
    {
      "epoch": 0.5735580038885288,
      "grad_norm": 0.500023365020752,
      "learning_rate": 1.8668405502611447e-05,
      "loss": 0.1968,
      "step": 1770
    },
    {
      "epoch": 0.5767984445884641,
      "grad_norm": 0.5411835312843323,
      "learning_rate": 1.865090981455278e-05,
      "loss": 0.1905,
      "step": 1780
    },
    {
      "epoch": 0.5800388852883992,
      "grad_norm": 0.4725927710533142,
      "learning_rate": 1.8633308247839616e-05,
      "loss": 0.1897,
      "step": 1790
    },
    {
      "epoch": 0.5832793259883344,
      "grad_norm": 0.484899640083313,
      "learning_rate": 1.8615601017897882e-05,
      "loss": 0.1921,
      "step": 1800
    },
    {
      "epoch": 0.5865197666882696,
      "grad_norm": 0.43722057342529297,
      "learning_rate": 1.8597788341446707e-05,
      "loss": 0.188,
      "step": 1810
    },
    {
      "epoch": 0.5897602073882048,
      "grad_norm": 0.4615707993507385,
      "learning_rate": 1.857987043649579e-05,
      "loss": 0.1847,
      "step": 1820
    },
    {
      "epoch": 0.59300064808814,
      "grad_norm": 0.47362610697746277,
      "learning_rate": 1.856184752234272e-05,
      "loss": 0.1906,
      "step": 1830
    },
    {
      "epoch": 0.5962410887880751,
      "grad_norm": 0.48887908458709717,
      "learning_rate": 1.8543719819570288e-05,
      "loss": 0.1931,
      "step": 1840
    },
    {
      "epoch": 0.5994815294880104,
      "grad_norm": 0.5036207437515259,
      "learning_rate": 1.8525487550043814e-05,
      "loss": 0.1894,
      "step": 1850
    },
    {
      "epoch": 0.6027219701879456,
      "grad_norm": 0.4553252160549164,
      "learning_rate": 1.85071509369084e-05,
      "loss": 0.1933,
      "step": 1860
    },
    {
      "epoch": 0.6059624108878807,
      "grad_norm": 0.447248637676239,
      "learning_rate": 1.84887102045862e-05,
      "loss": 0.1893,
      "step": 1870
    },
    {
      "epoch": 0.609202851587816,
      "grad_norm": 0.5117965936660767,
      "learning_rate": 1.847016557877372e-05,
      "loss": 0.1911,
      "step": 1880
    },
    {
      "epoch": 0.6124432922877512,
      "grad_norm": 0.5464609861373901,
      "learning_rate": 1.8451517286438978e-05,
      "loss": 0.1961,
      "step": 1890
    },
    {
      "epoch": 0.6156837329876863,
      "grad_norm": 0.5156446695327759,
      "learning_rate": 1.8432765555818797e-05,
      "loss": 0.1881,
      "step": 1900
    },
    {
      "epoch": 0.6189241736876215,
      "grad_norm": 0.43889179825782776,
      "learning_rate": 1.8413910616415977e-05,
      "loss": 0.1934,
      "step": 1910
    },
    {
      "epoch": 0.6221646143875567,
      "grad_norm": 0.4793156087398529,
      "learning_rate": 1.8394952698996485e-05,
      "loss": 0.19,
      "step": 1920
    },
    {
      "epoch": 0.6254050550874919,
      "grad_norm": 0.4899164140224457,
      "learning_rate": 1.837589203558665e-05,
      "loss": 0.1879,
      "step": 1930
    },
    {
      "epoch": 0.6286454957874271,
      "grad_norm": 0.47195228934288025,
      "learning_rate": 1.8356728859470298e-05,
      "loss": 0.1894,
      "step": 1940
    },
    {
      "epoch": 0.6318859364873622,
      "grad_norm": 0.5120038986206055,
      "learning_rate": 1.833746340518592e-05,
      "loss": 0.1887,
      "step": 1950
    },
    {
      "epoch": 0.6351263771872975,
      "grad_norm": 0.5484141111373901,
      "learning_rate": 1.8318095908523785e-05,
      "loss": 0.1877,
      "step": 1960
    },
    {
      "epoch": 0.6383668178872327,
      "grad_norm": 0.47096729278564453,
      "learning_rate": 1.8298626606523067e-05,
      "loss": 0.1913,
      "step": 1970
    },
    {
      "epoch": 0.6416072585871678,
      "grad_norm": 0.45310357213020325,
      "learning_rate": 1.827905573746893e-05,
      "loss": 0.1922,
      "step": 1980
    },
    {
      "epoch": 0.6448476992871031,
      "grad_norm": 0.46098390221595764,
      "learning_rate": 1.825938354088963e-05,
      "loss": 0.1859,
      "step": 1990
    },
    {
      "epoch": 0.6480881399870383,
      "grad_norm": 0.464498907327652,
      "learning_rate": 1.823961025755356e-05,
      "loss": 0.1865,
      "step": 2000
    },
    {
      "epoch": 0.6513285806869734,
      "grad_norm": 0.4729815423488617,
      "learning_rate": 1.8219736129466326e-05,
      "loss": 0.1845,
      "step": 2010
    },
    {
      "epoch": 0.6545690213869086,
      "grad_norm": 0.4783197045326233,
      "learning_rate": 1.8199761399867766e-05,
      "loss": 0.1867,
      "step": 2020
    },
    {
      "epoch": 0.6578094620868438,
      "grad_norm": 0.4915904700756073,
      "learning_rate": 1.8179686313228986e-05,
      "loss": 0.1848,
      "step": 2030
    },
    {
      "epoch": 0.661049902786779,
      "grad_norm": 0.4724244177341461,
      "learning_rate": 1.8159511115249367e-05,
      "loss": 0.1803,
      "step": 2040
    },
    {
      "epoch": 0.6642903434867142,
      "grad_norm": 0.4477594196796417,
      "learning_rate": 1.8139236052853557e-05,
      "loss": 0.1938,
      "step": 2050
    },
    {
      "epoch": 0.6675307841866494,
      "grad_norm": 0.5248154401779175,
      "learning_rate": 1.811886137418843e-05,
      "loss": 0.1891,
      "step": 2060
    },
    {
      "epoch": 0.6707712248865846,
      "grad_norm": 0.48006460070610046,
      "learning_rate": 1.8098387328620087e-05,
      "loss": 0.1849,
      "step": 2070
    },
    {
      "epoch": 0.6740116655865198,
      "grad_norm": 0.46011805534362793,
      "learning_rate": 1.8077814166730765e-05,
      "loss": 0.1921,
      "step": 2080
    },
    {
      "epoch": 0.6772521062864549,
      "grad_norm": 0.5849003195762634,
      "learning_rate": 1.8057142140315797e-05,
      "loss": 0.1903,
      "step": 2090
    },
    {
      "epoch": 0.6804925469863902,
      "grad_norm": 0.4715541899204254,
      "learning_rate": 1.8036371502380523e-05,
      "loss": 0.189,
      "step": 2100
    },
    {
      "epoch": 0.6837329876863253,
      "grad_norm": 0.4687066376209259,
      "learning_rate": 1.801550250713718e-05,
      "loss": 0.1906,
      "step": 2110
    },
    {
      "epoch": 0.6869734283862605,
      "grad_norm": 0.4934311807155609,
      "learning_rate": 1.799453541000182e-05,
      "loss": 0.1879,
      "step": 2120
    },
    {
      "epoch": 0.6902138690861958,
      "grad_norm": 0.43724846839904785,
      "learning_rate": 1.797347046759114e-05,
      "loss": 0.1924,
      "step": 2130
    },
    {
      "epoch": 0.6934543097861309,
      "grad_norm": 0.4656066298484802,
      "learning_rate": 1.7952307937719395e-05,
      "loss": 0.1845,
      "step": 2140
    },
    {
      "epoch": 0.6966947504860661,
      "grad_norm": 0.4574279487133026,
      "learning_rate": 1.7931048079395196e-05,
      "loss": 0.1858,
      "step": 2150
    },
    {
      "epoch": 0.6999351911860013,
      "grad_norm": 0.5140869617462158,
      "learning_rate": 1.790969115281837e-05,
      "loss": 0.191,
      "step": 2160
    },
    {
      "epoch": 0.7031756318859365,
      "grad_norm": 0.4511190354824066,
      "learning_rate": 1.788823741937675e-05,
      "loss": 0.1894,
      "step": 2170
    },
    {
      "epoch": 0.7064160725858717,
      "grad_norm": 0.47973155975341797,
      "learning_rate": 1.786668714164301e-05,
      "loss": 0.1913,
      "step": 2180
    },
    {
      "epoch": 0.7096565132858069,
      "grad_norm": 0.45750904083251953,
      "learning_rate": 1.784504058337141e-05,
      "loss": 0.1857,
      "step": 2190
    },
    {
      "epoch": 0.712896953985742,
      "grad_norm": 0.4866456389427185,
      "learning_rate": 1.7823298009494613e-05,
      "loss": 0.1866,
      "step": 2200
    },
    {
      "epoch": 0.7161373946856773,
      "grad_norm": 0.46466705203056335,
      "learning_rate": 1.7801459686120398e-05,
      "loss": 0.191,
      "step": 2210
    },
    {
      "epoch": 0.7193778353856124,
      "grad_norm": 0.5188704133033752,
      "learning_rate": 1.777952588052843e-05,
      "loss": 0.1857,
      "step": 2220
    },
    {
      "epoch": 0.7226182760855476,
      "grad_norm": 0.48869746923446655,
      "learning_rate": 1.7757496861166993e-05,
      "loss": 0.1859,
      "step": 2230
    },
    {
      "epoch": 0.7258587167854829,
      "grad_norm": 0.48946550488471985,
      "learning_rate": 1.7735372897649678e-05,
      "loss": 0.1885,
      "step": 2240
    },
    {
      "epoch": 0.729099157485418,
      "grad_norm": 0.4723547399044037,
      "learning_rate": 1.7713154260752112e-05,
      "loss": 0.1823,
      "step": 2250
    },
    {
      "epoch": 0.7323395981853532,
      "grad_norm": 0.4728027284145355,
      "learning_rate": 1.7690841222408625e-05,
      "loss": 0.186,
      "step": 2260
    },
    {
      "epoch": 0.7355800388852884,
      "grad_norm": 0.5300264358520508,
      "learning_rate": 1.766843405570893e-05,
      "loss": 0.1897,
      "step": 2270
    },
    {
      "epoch": 0.7388204795852236,
      "grad_norm": 0.4822717308998108,
      "learning_rate": 1.764593303489478e-05,
      "loss": 0.1857,
      "step": 2280
    },
    {
      "epoch": 0.7420609202851588,
      "grad_norm": 0.48458045721054077,
      "learning_rate": 1.7623338435356607e-05,
      "loss": 0.1875,
      "step": 2290
    },
    {
      "epoch": 0.7453013609850939,
      "grad_norm": 0.46104517579078674,
      "learning_rate": 1.760065053363016e-05,
      "loss": 0.1894,
      "step": 2300
    },
    {
      "epoch": 0.7485418016850292,
      "grad_norm": 0.5196328163146973,
      "learning_rate": 1.7577869607393108e-05,
      "loss": 0.1879,
      "step": 2310
    },
    {
      "epoch": 0.7517822423849644,
      "grad_norm": 0.45680558681488037,
      "learning_rate": 1.7554995935461656e-05,
      "loss": 0.1886,
      "step": 2320
    },
    {
      "epoch": 0.7550226830848995,
      "grad_norm": 0.5272301435470581,
      "learning_rate": 1.7532029797787126e-05,
      "loss": 0.1862,
      "step": 2330
    },
    {
      "epoch": 0.7582631237848347,
      "grad_norm": 0.526384174823761,
      "learning_rate": 1.7508971475452514e-05,
      "loss": 0.1866,
      "step": 2340
    },
    {
      "epoch": 0.76150356448477,
      "grad_norm": 0.46936360001564026,
      "learning_rate": 1.748582125066909e-05,
      "loss": 0.1866,
      "step": 2350
    },
    {
      "epoch": 0.7647440051847051,
      "grad_norm": 0.4961867332458496,
      "learning_rate": 1.7462579406772903e-05,
      "loss": 0.1862,
      "step": 2360
    },
    {
      "epoch": 0.7679844458846403,
      "grad_norm": 0.49790239334106445,
      "learning_rate": 1.743924622822134e-05,
      "loss": 0.1819,
      "step": 2370
    },
    {
      "epoch": 0.7712248865845756,
      "grad_norm": 0.4764527976512909,
      "learning_rate": 1.741582200058962e-05,
      "loss": 0.1843,
      "step": 2380
    },
    {
      "epoch": 0.7744653272845107,
      "grad_norm": 0.4726034700870514,
      "learning_rate": 1.7392307010567334e-05,
      "loss": 0.1823,
      "step": 2390
    },
    {
      "epoch": 0.7777057679844459,
      "grad_norm": 0.5794615149497986,
      "learning_rate": 1.7368701545954894e-05,
      "loss": 0.186,
      "step": 2400
    },
    {
      "epoch": 0.780946208684381,
      "grad_norm": 0.45800405740737915,
      "learning_rate": 1.734500589566006e-05,
      "loss": 0.1786,
      "step": 2410
    },
    {
      "epoch": 0.7841866493843163,
      "grad_norm": 0.4632687568664551,
      "learning_rate": 1.732122034969434e-05,
      "loss": 0.1872,
      "step": 2420
    },
    {
      "epoch": 0.7874270900842515,
      "grad_norm": 0.5002942085266113,
      "learning_rate": 1.7297345199169512e-05,
      "loss": 0.186,
      "step": 2430
    },
    {
      "epoch": 0.7906675307841866,
      "grad_norm": 0.5250207781791687,
      "learning_rate": 1.7273380736294e-05,
      "loss": 0.1875,
      "step": 2440
    },
    {
      "epoch": 0.7939079714841218,
      "grad_norm": 0.48551425337791443,
      "learning_rate": 1.7249327254369342e-05,
      "loss": 0.1852,
      "step": 2450
    },
    {
      "epoch": 0.7971484121840571,
      "grad_norm": 0.4709000885486603,
      "learning_rate": 1.722518504778657e-05,
      "loss": 0.1867,
      "step": 2460
    },
    {
      "epoch": 0.8003888528839922,
      "grad_norm": 0.48996952176094055,
      "learning_rate": 1.7200954412022624e-05,
      "loss": 0.1924,
      "step": 2470
    },
    {
      "epoch": 0.8036292935839274,
      "grad_norm": 0.46680697798728943,
      "learning_rate": 1.7176635643636725e-05,
      "loss": 0.185,
      "step": 2480
    },
    {
      "epoch": 0.8068697342838627,
      "grad_norm": 0.45148229598999023,
      "learning_rate": 1.715222904026676e-05,
      "loss": 0.1816,
      "step": 2490
    },
    {
      "epoch": 0.8101101749837978,
      "grad_norm": 0.5065425038337708,
      "learning_rate": 1.7127734900625625e-05,
      "loss": 0.1801,
      "step": 2500
    },
    {
      "epoch": 0.813350615683733,
      "grad_norm": 0.48429641127586365,
      "learning_rate": 1.710315352449757e-05,
      "loss": 0.1803,
      "step": 2510
    },
    {
      "epoch": 0.8165910563836681,
      "grad_norm": 0.5113956332206726,
      "learning_rate": 1.7078485212734542e-05,
      "loss": 0.1829,
      "step": 2520
    },
    {
      "epoch": 0.8198314970836034,
      "grad_norm": 0.47426071763038635,
      "learning_rate": 1.7053730267252493e-05,
      "loss": 0.1838,
      "step": 2530
    },
    {
      "epoch": 0.8230719377835386,
      "grad_norm": 0.49931254982948303,
      "learning_rate": 1.702888899102768e-05,
      "loss": 0.1835,
      "step": 2540
    },
    {
      "epoch": 0.8263123784834737,
      "grad_norm": 0.4841402769088745,
      "learning_rate": 1.7003961688092973e-05,
      "loss": 0.1886,
      "step": 2550
    },
    {
      "epoch": 0.829552819183409,
      "grad_norm": 0.4702390134334564,
      "learning_rate": 1.697894866353412e-05,
      "loss": 0.1873,
      "step": 2560
    },
    {
      "epoch": 0.8327932598833442,
      "grad_norm": 0.537070631980896,
      "learning_rate": 1.6953850223486018e-05,
      "loss": 0.1793,
      "step": 2570
    },
    {
      "epoch": 0.8360337005832793,
      "grad_norm": 0.48106786608695984,
      "learning_rate": 1.6928666675128962e-05,
      "loss": 0.1901,
      "step": 2580
    },
    {
      "epoch": 0.8392741412832145,
      "grad_norm": 0.4820539355278015,
      "learning_rate": 1.69033983266849e-05,
      "loss": 0.1831,
      "step": 2590
    },
    {
      "epoch": 0.8425145819831497,
      "grad_norm": 0.5056297779083252,
      "learning_rate": 1.6878045487413634e-05,
      "loss": 0.1843,
      "step": 2600
    },
    {
      "epoch": 0.8457550226830849,
      "grad_norm": 0.5037822127342224,
      "learning_rate": 1.685260846760907e-05,
      "loss": 0.1866,
      "step": 2610
    },
    {
      "epoch": 0.8489954633830201,
      "grad_norm": 0.45678162574768066,
      "learning_rate": 1.6827087578595384e-05,
      "loss": 0.1886,
      "step": 2620
    },
    {
      "epoch": 0.8522359040829552,
      "grad_norm": 0.4953486919403076,
      "learning_rate": 1.6801483132723234e-05,
      "loss": 0.182,
      "step": 2630
    },
    {
      "epoch": 0.8554763447828905,
      "grad_norm": 0.5122377276420593,
      "learning_rate": 1.677579544336594e-05,
      "loss": 0.1816,
      "step": 2640
    },
    {
      "epoch": 0.8587167854828257,
      "grad_norm": 0.5107054710388184,
      "learning_rate": 1.6750024824915636e-05,
      "loss": 0.1839,
      "step": 2650
    },
    {
      "epoch": 0.8619572261827608,
      "grad_norm": 0.4956507086753845,
      "learning_rate": 1.6724171592779422e-05,
      "loss": 0.1851,
      "step": 2660
    },
    {
      "epoch": 0.8651976668826961,
      "grad_norm": 0.49734944105148315,
      "learning_rate": 1.669823606337551e-05,
      "loss": 0.1833,
      "step": 2670
    },
    {
      "epoch": 0.8684381075826313,
      "grad_norm": 0.48624587059020996,
      "learning_rate": 1.6672218554129352e-05,
      "loss": 0.1855,
      "step": 2680
    },
    {
      "epoch": 0.8716785482825664,
      "grad_norm": 0.4572913348674774,
      "learning_rate": 1.6646119383469757e-05,
      "loss": 0.1775,
      "step": 2690
    },
    {
      "epoch": 0.8749189889825016,
      "grad_norm": 0.5104118585586548,
      "learning_rate": 1.6619938870824985e-05,
      "loss": 0.1888,
      "step": 2700
    },
    {
      "epoch": 0.8781594296824368,
      "grad_norm": 0.5315120816230774,
      "learning_rate": 1.6593677336618842e-05,
      "loss": 0.1825,
      "step": 2710
    },
    {
      "epoch": 0.881399870382372,
      "grad_norm": 0.47922977805137634,
      "learning_rate": 1.6567335102266752e-05,
      "loss": 0.1842,
      "step": 2720
    },
    {
      "epoch": 0.8846403110823072,
      "grad_norm": 0.49856844544410706,
      "learning_rate": 1.6540912490171847e-05,
      "loss": 0.1865,
      "step": 2730
    },
    {
      "epoch": 0.8878807517822424,
      "grad_norm": 0.4726937711238861,
      "learning_rate": 1.6514409823720988e-05,
      "loss": 0.1835,
      "step": 2740
    },
    {
      "epoch": 0.8911211924821776,
      "grad_norm": 0.4786529242992401,
      "learning_rate": 1.648782742728083e-05,
      "loss": 0.1828,
      "step": 2750
    },
    {
      "epoch": 0.8943616331821128,
      "grad_norm": 0.5357833504676819,
      "learning_rate": 1.646116562619384e-05,
      "loss": 0.1823,
      "step": 2760
    },
    {
      "epoch": 0.8976020738820479,
      "grad_norm": 0.5090686678886414,
      "learning_rate": 1.6434424746774328e-05,
      "loss": 0.1873,
      "step": 2770
    },
    {
      "epoch": 0.9008425145819832,
      "grad_norm": 0.5440138578414917,
      "learning_rate": 1.6407605116304433e-05,
      "loss": 0.1825,
      "step": 2780
    },
    {
      "epoch": 0.9040829552819183,
      "grad_norm": 0.5587863922119141,
      "learning_rate": 1.6380707063030147e-05,
      "loss": 0.1797,
      "step": 2790
    },
    {
      "epoch": 0.9073233959818535,
      "grad_norm": 0.5121341347694397,
      "learning_rate": 1.6353730916157264e-05,
      "loss": 0.181,
      "step": 2800
    },
    {
      "epoch": 0.9105638366817888,
      "grad_norm": 0.5011965036392212,
      "learning_rate": 1.6326677005847375e-05,
      "loss": 0.1846,
      "step": 2810
    },
    {
      "epoch": 0.9138042773817239,
      "grad_norm": 0.5092505216598511,
      "learning_rate": 1.6299545663213816e-05,
      "loss": 0.1903,
      "step": 2820
    },
    {
      "epoch": 0.9170447180816591,
      "grad_norm": 0.5263609290122986,
      "learning_rate": 1.6272337220317625e-05,
      "loss": 0.1845,
      "step": 2830
    },
    {
      "epoch": 0.9202851587815943,
      "grad_norm": 0.48992404341697693,
      "learning_rate": 1.624505201016346e-05,
      "loss": 0.1801,
      "step": 2840
    },
    {
      "epoch": 0.9235255994815295,
      "grad_norm": 0.5668559670448303,
      "learning_rate": 1.6217690366695547e-05,
      "loss": 0.1853,
      "step": 2850
    },
    {
      "epoch": 0.9267660401814647,
      "grad_norm": 0.5313438177108765,
      "learning_rate": 1.6190252624793577e-05,
      "loss": 0.1855,
      "step": 2860
    },
    {
      "epoch": 0.9300064808813999,
      "grad_norm": 0.5333547592163086,
      "learning_rate": 1.6162739120268606e-05,
      "loss": 0.1805,
      "step": 2870
    },
    {
      "epoch": 0.933246921581335,
      "grad_norm": 0.43964341282844543,
      "learning_rate": 1.6135150189858953e-05,
      "loss": 0.1851,
      "step": 2880
    },
    {
      "epoch": 0.9364873622812703,
      "grad_norm": 0.5966373085975647,
      "learning_rate": 1.6107486171226084e-05,
      "loss": 0.1892,
      "step": 2890
    },
    {
      "epoch": 0.9397278029812054,
      "grad_norm": 0.49173352122306824,
      "learning_rate": 1.607974740295046e-05,
      "loss": 0.1839,
      "step": 2900
    },
    {
      "epoch": 0.9429682436811406,
      "grad_norm": 0.5300976634025574,
      "learning_rate": 1.605193422452741e-05,
      "loss": 0.1808,
      "step": 2910
    },
    {
      "epoch": 0.9462086843810759,
      "grad_norm": 0.46686452627182007,
      "learning_rate": 1.6024046976362962e-05,
      "loss": 0.1812,
      "step": 2920
    },
    {
      "epoch": 0.949449125081011,
      "grad_norm": 0.5550686717033386,
      "learning_rate": 1.59960859997697e-05,
      "loss": 0.1841,
      "step": 2930
    },
    {
      "epoch": 0.9526895657809462,
      "grad_norm": 0.4720817506313324,
      "learning_rate": 1.5968051636962566e-05,
      "loss": 0.1865,
      "step": 2940
    },
    {
      "epoch": 0.9559300064808814,
      "grad_norm": 0.5330552458763123,
      "learning_rate": 1.5939944231054667e-05,
      "loss": 0.1822,
      "step": 2950
    },
    {
      "epoch": 0.9591704471808166,
      "grad_norm": 0.476426362991333,
      "learning_rate": 1.59117641260531e-05,
      "loss": 0.178,
      "step": 2960
    },
    {
      "epoch": 0.9624108878807518,
      "grad_norm": 0.5226211547851562,
      "learning_rate": 1.5883511666854712e-05,
      "loss": 0.1833,
      "step": 2970
    },
    {
      "epoch": 0.9656513285806869,
      "grad_norm": 0.5331970453262329,
      "learning_rate": 1.5855187199241917e-05,
      "loss": 0.1801,
      "step": 2980
    },
    {
      "epoch": 0.9688917692806222,
      "grad_norm": 0.5220275521278381,
      "learning_rate": 1.5826791069878423e-05,
      "loss": 0.1862,
      "step": 2990
    },
    {
      "epoch": 0.9721322099805574,
      "grad_norm": 0.5407083034515381,
      "learning_rate": 1.5798323626305008e-05,
      "loss": 0.1806,
      "step": 3000
    },
    {
      "epoch": 0.9753726506804925,
      "grad_norm": 0.5294139981269836,
      "learning_rate": 1.5769785216935277e-05,
      "loss": 0.1798,
      "step": 3010
    },
    {
      "epoch": 0.9786130913804277,
      "grad_norm": 0.5096558928489685,
      "learning_rate": 1.5741176191051377e-05,
      "loss": 0.1791,
      "step": 3020
    },
    {
      "epoch": 0.981853532080363,
      "grad_norm": 0.5364416241645813,
      "learning_rate": 1.571249689879974e-05,
      "loss": 0.1788,
      "step": 3030
    },
    {
      "epoch": 0.9850939727802981,
      "grad_norm": 0.5070610046386719,
      "learning_rate": 1.5683747691186778e-05,
      "loss": 0.1806,
      "step": 3040
    },
    {
      "epoch": 0.9883344134802333,
      "grad_norm": 0.4864497780799866,
      "learning_rate": 1.5654928920074616e-05,
      "loss": 0.1781,
      "step": 3050
    },
    {
      "epoch": 0.9915748541801686,
      "grad_norm": 0.4803544580936432,
      "learning_rate": 1.5626040938176744e-05,
      "loss": 0.1755,
      "step": 3060
    },
    {
      "epoch": 0.9948152948801037,
      "grad_norm": 0.4754418730735779,
      "learning_rate": 1.559708409905375e-05,
      "loss": 0.1771,
      "step": 3070
    },
    {
      "epoch": 0.9980557355800389,
      "grad_norm": 0.5137237310409546,
      "learning_rate": 1.556805875710895e-05,
      "loss": 0.1823,
      "step": 3080
    },
    {
      "epoch": 1.0012961762799741,
      "grad_norm": 0.5167588591575623,
      "learning_rate": 1.553896526758407e-05,
      "loss": 0.1823,
      "step": 3090
    },
    {
      "epoch": 1.0045366169799093,
      "grad_norm": 0.5408642888069153,
      "learning_rate": 1.55098039865549e-05,
      "loss": 0.182,
      "step": 3100
    },
    {
      "epoch": 1.0077770576798444,
      "grad_norm": 0.49669739603996277,
      "learning_rate": 1.5480575270926928e-05,
      "loss": 0.1767,
      "step": 3110
    },
    {
      "epoch": 1.0110174983797797,
      "grad_norm": 0.5018913149833679,
      "learning_rate": 1.5451279478430973e-05,
      "loss": 0.1774,
      "step": 3120
    },
    {
      "epoch": 1.0142579390797148,
      "grad_norm": 0.5139438509941101,
      "learning_rate": 1.542191696761882e-05,
      "loss": 0.1781,
      "step": 3130
    },
    {
      "epoch": 1.01749837977965,
      "grad_norm": 0.5484160780906677,
      "learning_rate": 1.539248809785881e-05,
      "loss": 0.1783,
      "step": 3140
    },
    {
      "epoch": 1.0207388204795853,
      "grad_norm": 0.5441487431526184,
      "learning_rate": 1.536299322933146e-05,
      "loss": 0.1739,
      "step": 3150
    },
    {
      "epoch": 1.0239792611795204,
      "grad_norm": 0.5419971942901611,
      "learning_rate": 1.5333432723025032e-05,
      "loss": 0.1787,
      "step": 3160
    },
    {
      "epoch": 1.0272197018794555,
      "grad_norm": 0.5062930583953857,
      "learning_rate": 1.5303806940731146e-05,
      "loss": 0.1708,
      "step": 3170
    },
    {
      "epoch": 1.030460142579391,
      "grad_norm": 0.5411158204078674,
      "learning_rate": 1.5274116245040337e-05,
      "loss": 0.1815,
      "step": 3180
    },
    {
      "epoch": 1.033700583279326,
      "grad_norm": 0.5091112852096558,
      "learning_rate": 1.524436099933761e-05,
      "loss": 0.184,
      "step": 3190
    },
    {
      "epoch": 1.0369410239792611,
      "grad_norm": 0.5070368051528931,
      "learning_rate": 1.521454156779799e-05,
      "loss": 0.1793,
      "step": 3200
    },
    {
      "epoch": 1.0401814646791965,
      "grad_norm": 0.5206501483917236,
      "learning_rate": 1.518465831538209e-05,
      "loss": 0.1705,
      "step": 3210
    },
    {
      "epoch": 1.0434219053791316,
      "grad_norm": 0.5195854306221008,
      "learning_rate": 1.5154711607831618e-05,
      "loss": 0.1749,
      "step": 3220
    },
    {
      "epoch": 1.0466623460790667,
      "grad_norm": 0.5219631791114807,
      "learning_rate": 1.5124701811664918e-05,
      "loss": 0.177,
      "step": 3230
    },
    {
      "epoch": 1.0499027867790018,
      "grad_norm": 0.5267064571380615,
      "learning_rate": 1.509462929417247e-05,
      "loss": 0.1845,
      "step": 3240
    },
    {
      "epoch": 1.0531432274789372,
      "grad_norm": 0.5196012854576111,
      "learning_rate": 1.5064494423412404e-05,
      "loss": 0.1788,
      "step": 3250
    },
    {
      "epoch": 1.0563836681788723,
      "grad_norm": 0.49656054377555847,
      "learning_rate": 1.5034297568205994e-05,
      "loss": 0.182,
      "step": 3260
    },
    {
      "epoch": 1.0596241088788074,
      "grad_norm": 0.4971262514591217,
      "learning_rate": 1.500403909813314e-05,
      "loss": 0.176,
      "step": 3270
    },
    {
      "epoch": 1.0628645495787428,
      "grad_norm": 0.525418758392334,
      "learning_rate": 1.4973719383527849e-05,
      "loss": 0.174,
      "step": 3280
    },
    {
      "epoch": 1.0661049902786779,
      "grad_norm": 0.5529376864433289,
      "learning_rate": 1.4943338795473703e-05,
      "loss": 0.1794,
      "step": 3290
    },
    {
      "epoch": 1.069345430978613,
      "grad_norm": 0.557632565498352,
      "learning_rate": 1.4912897705799317e-05,
      "loss": 0.1718,
      "step": 3300
    },
    {
      "epoch": 1.0725858716785484,
      "grad_norm": 0.4897734224796295,
      "learning_rate": 1.4882396487073773e-05,
      "loss": 0.1756,
      "step": 3310
    },
    {
      "epoch": 1.0758263123784835,
      "grad_norm": 0.5540860891342163,
      "learning_rate": 1.4851835512602093e-05,
      "loss": 0.1794,
      "step": 3320
    },
    {
      "epoch": 1.0790667530784186,
      "grad_norm": 0.5266072750091553,
      "learning_rate": 1.4821215156420638e-05,
      "loss": 0.1769,
      "step": 3330
    },
    {
      "epoch": 1.082307193778354,
      "grad_norm": 0.5190185904502869,
      "learning_rate": 1.4790535793292545e-05,
      "loss": 0.1758,
      "step": 3340
    },
    {
      "epoch": 1.085547634478289,
      "grad_norm": 0.5373579263687134,
      "learning_rate": 1.4759797798703144e-05,
      "loss": 0.1778,
      "step": 3350
    },
    {
      "epoch": 1.0887880751782242,
      "grad_norm": 0.5178830027580261,
      "learning_rate": 1.472900154885535e-05,
      "loss": 0.167,
      "step": 3360
    },
    {
      "epoch": 1.0920285158781595,
      "grad_norm": 0.5227540135383606,
      "learning_rate": 1.4698147420665065e-05,
      "loss": 0.1793,
      "step": 3370
    },
    {
      "epoch": 1.0952689565780946,
      "grad_norm": 0.5192795395851135,
      "learning_rate": 1.4667235791756573e-05,
      "loss": 0.1733,
      "step": 3380
    },
    {
      "epoch": 1.0985093972780298,
      "grad_norm": 0.576714038848877,
      "learning_rate": 1.4636267040457899e-05,
      "loss": 0.1779,
      "step": 3390
    },
    {
      "epoch": 1.101749837977965,
      "grad_norm": 0.5015330910682678,
      "learning_rate": 1.4605241545796199e-05,
      "loss": 0.1756,
      "step": 3400
    },
    {
      "epoch": 1.1049902786779002,
      "grad_norm": 0.5293465256690979,
      "learning_rate": 1.457415968749311e-05,
      "loss": 0.1709,
      "step": 3410
    },
    {
      "epoch": 1.1082307193778353,
      "grad_norm": 0.49473804235458374,
      "learning_rate": 1.4543021845960104e-05,
      "loss": 0.1739,
      "step": 3420
    },
    {
      "epoch": 1.1114711600777705,
      "grad_norm": 0.5008044838905334,
      "learning_rate": 1.4511828402293833e-05,
      "loss": 0.168,
      "step": 3430
    },
    {
      "epoch": 1.1147116007777058,
      "grad_norm": 0.45724061131477356,
      "learning_rate": 1.4480579738271463e-05,
      "loss": 0.1778,
      "step": 3440
    },
    {
      "epoch": 1.117952041477641,
      "grad_norm": 0.5711448192596436,
      "learning_rate": 1.4449276236346e-05,
      "loss": 0.1739,
      "step": 3450
    },
    {
      "epoch": 1.121192482177576,
      "grad_norm": 0.5159705281257629,
      "learning_rate": 1.441791827964163e-05,
      "loss": 0.1731,
      "step": 3460
    },
    {
      "epoch": 1.1244329228775114,
      "grad_norm": 0.5605918765068054,
      "learning_rate": 1.4386506251948986e-05,
      "loss": 0.1721,
      "step": 3470
    },
    {
      "epoch": 1.1276733635774465,
      "grad_norm": 0.5064542889595032,
      "learning_rate": 1.4355040537720491e-05,
      "loss": 0.1741,
      "step": 3480
    },
    {
      "epoch": 1.1309138042773816,
      "grad_norm": 0.53163081407547,
      "learning_rate": 1.4323521522065643e-05,
      "loss": 0.1771,
      "step": 3490
    },
    {
      "epoch": 1.134154244977317,
      "grad_norm": 0.47870972752571106,
      "learning_rate": 1.429194959074629e-05,
      "loss": 0.1727,
      "step": 3500
    },
    {
      "epoch": 1.137394685677252,
      "grad_norm": 0.5159515142440796,
      "learning_rate": 1.426032513017191e-05,
      "loss": 0.1737,
      "step": 3510
    },
    {
      "epoch": 1.1406351263771872,
      "grad_norm": 0.5019080638885498,
      "learning_rate": 1.4228648527394905e-05,
      "loss": 0.176,
      "step": 3520
    },
    {
      "epoch": 1.1438755670771226,
      "grad_norm": 0.5196112990379333,
      "learning_rate": 1.419692017010583e-05,
      "loss": 0.172,
      "step": 3530
    },
    {
      "epoch": 1.1471160077770577,
      "grad_norm": 0.49744969606399536,
      "learning_rate": 1.416514044662867e-05,
      "loss": 0.1693,
      "step": 3540
    },
    {
      "epoch": 1.1503564484769928,
      "grad_norm": 0.5203508138656616,
      "learning_rate": 1.4133309745916084e-05,
      "loss": 0.1749,
      "step": 3550
    },
    {
      "epoch": 1.1535968891769282,
      "grad_norm": 0.5384011268615723,
      "learning_rate": 1.4101428457544643e-05,
      "loss": 0.1738,
      "step": 3560
    },
    {
      "epoch": 1.1568373298768633,
      "grad_norm": 0.544688880443573,
      "learning_rate": 1.4069496971710057e-05,
      "loss": 0.1785,
      "step": 3570
    },
    {
      "epoch": 1.1600777705767984,
      "grad_norm": 0.5399643182754517,
      "learning_rate": 1.4037515679222408e-05,
      "loss": 0.1719,
      "step": 3580
    },
    {
      "epoch": 1.1633182112767337,
      "grad_norm": 0.5244926810264587,
      "learning_rate": 1.4005484971501357e-05,
      "loss": 0.1715,
      "step": 3590
    },
    {
      "epoch": 1.1665586519766689,
      "grad_norm": 0.5466824769973755,
      "learning_rate": 1.3973405240571366e-05,
      "loss": 0.1787,
      "step": 3600
    },
    {
      "epoch": 1.169799092676604,
      "grad_norm": 0.5138394236564636,
      "learning_rate": 1.394127687905689e-05,
      "loss": 0.1737,
      "step": 3610
    },
    {
      "epoch": 1.173039533376539,
      "grad_norm": 0.5359494686126709,
      "learning_rate": 1.3909100280177569e-05,
      "loss": 0.1748,
      "step": 3620
    },
    {
      "epoch": 1.1762799740764744,
      "grad_norm": 0.530957818031311,
      "learning_rate": 1.3876875837743431e-05,
      "loss": 0.1764,
      "step": 3630
    },
    {
      "epoch": 1.1795204147764096,
      "grad_norm": 0.5131997466087341,
      "learning_rate": 1.3844603946150057e-05,
      "loss": 0.1756,
      "step": 3640
    },
    {
      "epoch": 1.1827608554763447,
      "grad_norm": 0.5705198645591736,
      "learning_rate": 1.3812285000373757e-05,
      "loss": 0.1734,
      "step": 3650
    },
    {
      "epoch": 1.18600129617628,
      "grad_norm": 0.582064688205719,
      "learning_rate": 1.3779919395966743e-05,
      "loss": 0.1723,
      "step": 3660
    },
    {
      "epoch": 1.1892417368762151,
      "grad_norm": 0.5047677755355835,
      "learning_rate": 1.3747507529052282e-05,
      "loss": 0.1727,
      "step": 3670
    },
    {
      "epoch": 1.1924821775761503,
      "grad_norm": 0.5395809412002563,
      "learning_rate": 1.3715049796319842e-05,
      "loss": 0.1736,
      "step": 3680
    },
    {
      "epoch": 1.1957226182760856,
      "grad_norm": 0.5670037269592285,
      "learning_rate": 1.3682546595020255e-05,
      "loss": 0.1754,
      "step": 3690
    },
    {
      "epoch": 1.1989630589760207,
      "grad_norm": 0.5584481954574585,
      "learning_rate": 1.3649998322960833e-05,
      "loss": 0.1745,
      "step": 3700
    },
    {
      "epoch": 1.2022034996759559,
      "grad_norm": 0.5736880302429199,
      "learning_rate": 1.361740537850052e-05,
      "loss": 0.1788,
      "step": 3710
    },
    {
      "epoch": 1.2054439403758912,
      "grad_norm": 0.5240222811698914,
      "learning_rate": 1.3584768160544995e-05,
      "loss": 0.1739,
      "step": 3720
    },
    {
      "epoch": 1.2086843810758263,
      "grad_norm": 0.5332230925559998,
      "learning_rate": 1.3552087068541811e-05,
      "loss": 0.1782,
      "step": 3730
    },
    {
      "epoch": 1.2119248217757614,
      "grad_norm": 0.5253359079360962,
      "learning_rate": 1.351936250247549e-05,
      "loss": 0.171,
      "step": 3740
    },
    {
      "epoch": 1.2151652624756968,
      "grad_norm": 0.5426280498504639,
      "learning_rate": 1.348659486286264e-05,
      "loss": 0.1717,
      "step": 3750
    },
    {
      "epoch": 1.218405703175632,
      "grad_norm": 0.5461429953575134,
      "learning_rate": 1.345378455074704e-05,
      "loss": 0.1801,
      "step": 3760
    },
    {
      "epoch": 1.221646143875567,
      "grad_norm": 0.5229367613792419,
      "learning_rate": 1.3420931967694746e-05,
      "loss": 0.1753,
      "step": 3770
    },
    {
      "epoch": 1.2248865845755024,
      "grad_norm": 0.5696377754211426,
      "learning_rate": 1.338803751578916e-05,
      "loss": 0.1745,
      "step": 3780
    },
    {
      "epoch": 1.2281270252754375,
      "grad_norm": 0.5486393570899963,
      "learning_rate": 1.3355101597626123e-05,
      "loss": 0.1753,
      "step": 3790
    },
    {
      "epoch": 1.2313674659753726,
      "grad_norm": 0.4879927635192871,
      "learning_rate": 1.3322124616308987e-05,
      "loss": 0.1731,
      "step": 3800
    },
    {
      "epoch": 1.2346079066753077,
      "grad_norm": 0.5675704479217529,
      "learning_rate": 1.3289106975443666e-05,
      "loss": 0.1753,
      "step": 3810
    },
    {
      "epoch": 1.237848347375243,
      "grad_norm": 0.5567381978034973,
      "learning_rate": 1.3256049079133715e-05,
      "loss": 0.1728,
      "step": 3820
    },
    {
      "epoch": 1.2410887880751782,
      "grad_norm": 0.5582255721092224,
      "learning_rate": 1.3222951331975373e-05,
      "loss": 0.1698,
      "step": 3830
    },
    {
      "epoch": 1.2443292287751135,
      "grad_norm": 0.5076599717140198,
      "learning_rate": 1.3189814139052615e-05,
      "loss": 0.179,
      "step": 3840
    },
    {
      "epoch": 1.2475696694750487,
      "grad_norm": 0.5753747820854187,
      "learning_rate": 1.3156637905932196e-05,
      "loss": 0.1738,
      "step": 3850
    },
    {
      "epoch": 1.2508101101749838,
      "grad_norm": 0.5100031495094299,
      "learning_rate": 1.312342303865868e-05,
      "loss": 0.1686,
      "step": 3860
    },
    {
      "epoch": 1.254050550874919,
      "grad_norm": 0.6092217564582825,
      "learning_rate": 1.3090169943749475e-05,
      "loss": 0.1759,
      "step": 3870
    },
    {
      "epoch": 1.2572909915748542,
      "grad_norm": 0.5460062623023987,
      "learning_rate": 1.3056879028189866e-05,
      "loss": 0.1756,
      "step": 3880
    },
    {
      "epoch": 1.2605314322747894,
      "grad_norm": 0.5317044258117676,
      "learning_rate": 1.3023550699428015e-05,
      "loss": 0.173,
      "step": 3890
    },
    {
      "epoch": 1.2637718729747245,
      "grad_norm": 0.5666733980178833,
      "learning_rate": 1.2990185365369993e-05,
      "loss": 0.1743,
      "step": 3900
    },
    {
      "epoch": 1.2670123136746598,
      "grad_norm": 0.5465630888938904,
      "learning_rate": 1.2956783434374778e-05,
      "loss": 0.1774,
      "step": 3910
    },
    {
      "epoch": 1.270252754374595,
      "grad_norm": 0.614748477935791,
      "learning_rate": 1.2923345315249251e-05,
      "loss": 0.1737,
      "step": 3920
    },
    {
      "epoch": 1.27349319507453,
      "grad_norm": 0.5935555696487427,
      "learning_rate": 1.288987141724321e-05,
      "loss": 0.1701,
      "step": 3930
    },
    {
      "epoch": 1.2767336357744652,
      "grad_norm": 0.5161668658256531,
      "learning_rate": 1.285636215004435e-05,
      "loss": 0.176,
      "step": 3940
    },
    {
      "epoch": 1.2799740764744005,
      "grad_norm": 0.5814167857170105,
      "learning_rate": 1.2822817923773243e-05,
      "loss": 0.1748,
      "step": 3950
    },
    {
      "epoch": 1.2832145171743357,
      "grad_norm": 0.5527446269989014,
      "learning_rate": 1.2789239148978331e-05,
      "loss": 0.1729,
      "step": 3960
    },
    {
      "epoch": 1.286454957874271,
      "grad_norm": 0.5252190828323364,
      "learning_rate": 1.27556262366309e-05,
      "loss": 0.1737,
      "step": 3970
    },
    {
      "epoch": 1.2896953985742061,
      "grad_norm": 0.5451162457466125,
      "learning_rate": 1.272197959812004e-05,
      "loss": 0.175,
      "step": 3980
    },
    {
      "epoch": 1.2929358392741412,
      "grad_norm": 0.5492450594902039,
      "learning_rate": 1.2688299645247618e-05,
      "loss": 0.1709,
      "step": 3990
    },
    {
      "epoch": 1.2961762799740764,
      "grad_norm": 0.5237749218940735,
      "learning_rate": 1.2654586790223236e-05,
      "loss": 0.1684,
      "step": 4000
    },
    {
      "epoch": 1.2994167206740117,
      "grad_norm": 0.5415225625038147,
      "learning_rate": 1.2620841445659182e-05,
      "loss": 0.181,
      "step": 4010
    },
    {
      "epoch": 1.3026571613739468,
      "grad_norm": 0.5365909337997437,
      "learning_rate": 1.2587064024565399e-05,
      "loss": 0.1724,
      "step": 4020
    },
    {
      "epoch": 1.3058976020738822,
      "grad_norm": 0.5526332259178162,
      "learning_rate": 1.2553254940344395e-05,
      "loss": 0.1733,
      "step": 4030
    },
    {
      "epoch": 1.3091380427738173,
      "grad_norm": 0.5835829377174377,
      "learning_rate": 1.2519414606786215e-05,
      "loss": 0.17,
      "step": 4040
    },
    {
      "epoch": 1.3123784834737524,
      "grad_norm": 0.5292119979858398,
      "learning_rate": 1.2485543438063369e-05,
      "loss": 0.1738,
      "step": 4050
    },
    {
      "epoch": 1.3156189241736875,
      "grad_norm": 0.5441445112228394,
      "learning_rate": 1.2451641848725746e-05,
      "loss": 0.1675,
      "step": 4060
    },
    {
      "epoch": 1.3188593648736229,
      "grad_norm": 0.5619595050811768,
      "learning_rate": 1.2417710253695565e-05,
      "loss": 0.175,
      "step": 4070
    },
    {
      "epoch": 1.322099805573558,
      "grad_norm": 0.5476670861244202,
      "learning_rate": 1.2383749068262286e-05,
      "loss": 0.1729,
      "step": 4080
    },
    {
      "epoch": 1.3253402462734931,
      "grad_norm": 0.598755419254303,
      "learning_rate": 1.2349758708077514e-05,
      "loss": 0.1751,
      "step": 4090
    },
    {
      "epoch": 1.3285806869734285,
      "grad_norm": 0.5049954652786255,
      "learning_rate": 1.2315739589149938e-05,
      "loss": 0.1764,
      "step": 4100
    },
    {
      "epoch": 1.3318211276733636,
      "grad_norm": 0.5390908718109131,
      "learning_rate": 1.2281692127840219e-05,
      "loss": 0.1707,
      "step": 4110
    },
    {
      "epoch": 1.3350615683732987,
      "grad_norm": 0.5615761876106262,
      "learning_rate": 1.2247616740855898e-05,
      "loss": 0.1723,
      "step": 4120
    },
    {
      "epoch": 1.3383020090732338,
      "grad_norm": 0.5497929453849792,
      "learning_rate": 1.2213513845246312e-05,
      "loss": 0.1772,
      "step": 4130
    },
    {
      "epoch": 1.3415424497731692,
      "grad_norm": 0.5469362735748291,
      "learning_rate": 1.217938385839746e-05,
      "loss": 0.1735,
      "step": 4140
    },
    {
      "epoch": 1.3447828904731043,
      "grad_norm": 0.560838520526886,
      "learning_rate": 1.2145227198026919e-05,
      "loss": 0.1767,
      "step": 4150
    },
    {
      "epoch": 1.3480233311730396,
      "grad_norm": 0.513076663017273,
      "learning_rate": 1.2111044282178728e-05,
      "loss": 0.1694,
      "step": 4160
    },
    {
      "epoch": 1.3512637718729748,
      "grad_norm": 0.5817582011222839,
      "learning_rate": 1.207683552921826e-05,
      "loss": 0.171,
      "step": 4170
    },
    {
      "epoch": 1.3545042125729099,
      "grad_norm": 0.6197202801704407,
      "learning_rate": 1.204260135782711e-05,
      "loss": 0.1682,
      "step": 4180
    },
    {
      "epoch": 1.357744653272845,
      "grad_norm": 0.5316491723060608,
      "learning_rate": 1.200834218699798e-05,
      "loss": 0.1702,
      "step": 4190
    },
    {
      "epoch": 1.3609850939727803,
      "grad_norm": 0.5504481196403503,
      "learning_rate": 1.1974058436029523e-05,
      "loss": 0.1787,
      "step": 4200
    },
    {
      "epoch": 1.3642255346727155,
      "grad_norm": 0.5589761137962341,
      "learning_rate": 1.1939750524521238e-05,
      "loss": 0.1757,
      "step": 4210
    },
    {
      "epoch": 1.3674659753726508,
      "grad_norm": 0.5250048041343689,
      "learning_rate": 1.190541887236833e-05,
      "loss": 0.1739,
      "step": 4220
    },
    {
      "epoch": 1.370706416072586,
      "grad_norm": 0.5529565215110779,
      "learning_rate": 1.1871063899756562e-05,
      "loss": 0.1745,
      "step": 4230
    },
    {
      "epoch": 1.373946856772521,
      "grad_norm": 0.5777830481529236,
      "learning_rate": 1.1836686027157111e-05,
      "loss": 0.1757,
      "step": 4240
    },
    {
      "epoch": 1.3771872974724562,
      "grad_norm": 0.5738629698753357,
      "learning_rate": 1.1802285675321437e-05,
      "loss": 0.17,
      "step": 4250
    },
    {
      "epoch": 1.3804277381723915,
      "grad_norm": 0.5849077701568604,
      "learning_rate": 1.1767863265276118e-05,
      "loss": 0.1699,
      "step": 4260
    },
    {
      "epoch": 1.3836681788723266,
      "grad_norm": 0.5550866723060608,
      "learning_rate": 1.1733419218317701e-05,
      "loss": 0.173,
      "step": 4270
    },
    {
      "epoch": 1.3869086195722617,
      "grad_norm": 0.5727715492248535,
      "learning_rate": 1.1698953956007557e-05,
      "loss": 0.1698,
      "step": 4280
    },
    {
      "epoch": 1.390149060272197,
      "grad_norm": 0.5354244112968445,
      "learning_rate": 1.1664467900166699e-05,
      "loss": 0.1765,
      "step": 4290
    },
    {
      "epoch": 1.3933895009721322,
      "grad_norm": 0.5648941397666931,
      "learning_rate": 1.1629961472870643e-05,
      "loss": 0.1769,
      "step": 4300
    },
    {
      "epoch": 1.3966299416720673,
      "grad_norm": 0.5081478953361511,
      "learning_rate": 1.159543509644423e-05,
      "loss": 0.1781,
      "step": 4310
    },
    {
      "epoch": 1.3998703823720027,
      "grad_norm": 0.5479035973548889,
      "learning_rate": 1.1560889193456448e-05,
      "loss": 0.1741,
      "step": 4320
    },
    {
      "epoch": 1.4031108230719378,
      "grad_norm": 0.5613148212432861,
      "learning_rate": 1.152632418671529e-05,
      "loss": 0.1765,
      "step": 4330
    },
    {
      "epoch": 1.406351263771873,
      "grad_norm": 0.5772766470909119,
      "learning_rate": 1.1491740499262546e-05,
      "loss": 0.1677,
      "step": 4340
    },
    {
      "epoch": 1.4095917044718083,
      "grad_norm": 0.5339111089706421,
      "learning_rate": 1.1457138554368637e-05,
      "loss": 0.1755,
      "step": 4350
    },
    {
      "epoch": 1.4128321451717434,
      "grad_norm": 0.6035047769546509,
      "learning_rate": 1.1422518775527453e-05,
      "loss": 0.1742,
      "step": 4360
    },
    {
      "epoch": 1.4160725858716785,
      "grad_norm": 0.5601799488067627,
      "learning_rate": 1.1387881586451141e-05,
      "loss": 0.1764,
      "step": 4370
    },
    {
      "epoch": 1.4193130265716136,
      "grad_norm": 0.5417890548706055,
      "learning_rate": 1.1353227411064936e-05,
      "loss": 0.1797,
      "step": 4380
    },
    {
      "epoch": 1.422553467271549,
      "grad_norm": 0.5147412419319153,
      "learning_rate": 1.1318556673501966e-05,
      "loss": 0.1681,
      "step": 4390
    },
    {
      "epoch": 1.425793907971484,
      "grad_norm": 0.5594676733016968,
      "learning_rate": 1.128386979809807e-05,
      "loss": 0.1741,
      "step": 4400
    },
    {
      "epoch": 1.4290343486714194,
      "grad_norm": 0.5687634348869324,
      "learning_rate": 1.1249167209386594e-05,
      "loss": 0.1759,
      "step": 4410
    },
    {
      "epoch": 1.4322747893713546,
      "grad_norm": 0.5271673202514648,
      "learning_rate": 1.12144493320932e-05,
      "loss": 0.1701,
      "step": 4420
    },
    {
      "epoch": 1.4355152300712897,
      "grad_norm": 0.6086588501930237,
      "learning_rate": 1.1179716591130666e-05,
      "loss": 0.1784,
      "step": 4430
    },
    {
      "epoch": 1.4387556707712248,
      "grad_norm": 0.5162380337715149,
      "learning_rate": 1.1144969411593693e-05,
      "loss": 0.1774,
      "step": 4440
    },
    {
      "epoch": 1.4419961114711601,
      "grad_norm": 0.5433120131492615,
      "learning_rate": 1.1110208218753686e-05,
      "loss": 0.1684,
      "step": 4450
    },
    {
      "epoch": 1.4452365521710953,
      "grad_norm": 0.5378836989402771,
      "learning_rate": 1.1075433438053567e-05,
      "loss": 0.1738,
      "step": 4460
    },
    {
      "epoch": 1.4484769928710304,
      "grad_norm": 0.567750871181488,
      "learning_rate": 1.1040645495102556e-05,
      "loss": 0.1667,
      "step": 4470
    },
    {
      "epoch": 1.4517174335709657,
      "grad_norm": 0.5129477977752686,
      "learning_rate": 1.1005844815670969e-05,
      "loss": 0.1669,
      "step": 4480
    },
    {
      "epoch": 1.4549578742709008,
      "grad_norm": 0.5568174123764038,
      "learning_rate": 1.0971031825684998e-05,
      "loss": 0.1681,
      "step": 4490
    },
    {
      "epoch": 1.458198314970836,
      "grad_norm": 0.5554882287979126,
      "learning_rate": 1.0936206951221517e-05,
      "loss": 0.1757,
      "step": 4500
    },
    {
      "epoch": 1.4614387556707713,
      "grad_norm": 0.5748602747917175,
      "learning_rate": 1.090137061850284e-05,
      "loss": 0.1702,
      "step": 4510
    },
    {
      "epoch": 1.4646791963707064,
      "grad_norm": 0.49452003836631775,
      "learning_rate": 1.0866523253891525e-05,
      "loss": 0.1713,
      "step": 4520
    },
    {
      "epoch": 1.4679196370706415,
      "grad_norm": 0.5603742003440857,
      "learning_rate": 1.0831665283885151e-05,
      "loss": 0.1745,
      "step": 4530
    },
    {
      "epoch": 1.471160077770577,
      "grad_norm": 0.5556715726852417,
      "learning_rate": 1.0796797135111093e-05,
      "loss": 0.1683,
      "step": 4540
    },
    {
      "epoch": 1.474400518470512,
      "grad_norm": 0.5676223635673523,
      "learning_rate": 1.076191923432131e-05,
      "loss": 0.1688,
      "step": 4550
    },
    {
      "epoch": 1.4776409591704471,
      "grad_norm": 0.5665457844734192,
      "learning_rate": 1.0727032008387107e-05,
      "loss": 0.1766,
      "step": 4560
    },
    {
      "epoch": 1.4808813998703823,
      "grad_norm": 0.6212825775146484,
      "learning_rate": 1.0692135884293926e-05,
      "loss": 0.1753,
      "step": 4570
    },
    {
      "epoch": 1.4841218405703176,
      "grad_norm": 0.5197409987449646,
      "learning_rate": 1.0657231289136118e-05,
      "loss": 0.1692,
      "step": 4580
    },
    {
      "epoch": 1.4873622812702527,
      "grad_norm": 0.584233820438385,
      "learning_rate": 1.0622318650111703e-05,
      "loss": 0.1717,
      "step": 4590
    },
    {
      "epoch": 1.490602721970188,
      "grad_norm": 0.5444473624229431,
      "learning_rate": 1.0587398394517148e-05,
      "loss": 0.165,
      "step": 4600
    },
    {
      "epoch": 1.4938431626701232,
      "grad_norm": 0.5183011889457703,
      "learning_rate": 1.0552470949742152e-05,
      "loss": 0.1752,
      "step": 4610
    },
    {
      "epoch": 1.4970836033700583,
      "grad_norm": 0.6103681921958923,
      "learning_rate": 1.0517536743264393e-05,
      "loss": 0.1755,
      "step": 4620
    },
    {
      "epoch": 1.5003240440699934,
      "grad_norm": 0.5989363789558411,
      "learning_rate": 1.0482596202644304e-05,
      "loss": 0.1713,
      "step": 4630
    },
    {
      "epoch": 1.5035644847699285,
      "grad_norm": 0.5702422857284546,
      "learning_rate": 1.0447649755519849e-05,
      "loss": 0.168,
      "step": 4640
    },
    {
      "epoch": 1.5068049254698639,
      "grad_norm": 0.5801076889038086,
      "learning_rate": 1.0412697829601276e-05,
      "loss": 0.1705,
      "step": 4650
    },
    {
      "epoch": 1.5100453661697992,
      "grad_norm": 0.5960607528686523,
      "learning_rate": 1.0377740852665893e-05,
      "loss": 0.1728,
      "step": 4660
    },
    {
      "epoch": 1.5132858068697344,
      "grad_norm": 0.5797833800315857,
      "learning_rate": 1.0342779252552822e-05,
      "loss": 0.1715,
      "step": 4670
    },
    {
      "epoch": 1.5165262475696695,
      "grad_norm": 0.6114943623542786,
      "learning_rate": 1.0307813457157773e-05,
      "loss": 0.1691,
      "step": 4680
    },
    {
      "epoch": 1.5197666882696046,
      "grad_norm": 0.5432888269424438,
      "learning_rate": 1.0272843894427797e-05,
      "loss": 0.1672,
      "step": 4690
    },
    {
      "epoch": 1.5230071289695397,
      "grad_norm": 0.5608060359954834,
      "learning_rate": 1.0237870992356061e-05,
      "loss": 0.1731,
      "step": 4700
    },
    {
      "epoch": 1.526247569669475,
      "grad_norm": 0.5969025492668152,
      "learning_rate": 1.0202895178976591e-05,
      "loss": 0.1649,
      "step": 4710
    },
    {
      "epoch": 1.5294880103694104,
      "grad_norm": 0.5559171438217163,
      "learning_rate": 1.016791688235906e-05,
      "loss": 0.1706,
      "step": 4720
    },
    {
      "epoch": 1.5327284510693455,
      "grad_norm": 0.5452934503555298,
      "learning_rate": 1.0132936530603515e-05,
      "loss": 0.1754,
      "step": 4730
    },
    {
      "epoch": 1.5359688917692806,
      "grad_norm": 0.5375877618789673,
      "learning_rate": 1.0097954551835172e-05,
      "loss": 0.1655,
      "step": 4740
    },
    {
      "epoch": 1.5392093324692158,
      "grad_norm": 0.551207959651947,
      "learning_rate": 1.0062971374199155e-05,
      "loss": 0.1692,
      "step": 4750
    },
    {
      "epoch": 1.5424497731691509,
      "grad_norm": 0.5836418867111206,
      "learning_rate": 1.0027987425855256e-05,
      "loss": 0.1711,
      "step": 4760
    },
    {
      "epoch": 1.5456902138690862,
      "grad_norm": 0.5771447420120239,
      "learning_rate": 9.993003134972703e-06,
      "loss": 0.1704,
      "step": 4770
    },
    {
      "epoch": 1.5489306545690213,
      "grad_norm": 0.5312148928642273,
      "learning_rate": 9.958018929724921e-06,
      "loss": 0.1736,
      "step": 4780
    },
    {
      "epoch": 1.5521710952689567,
      "grad_norm": 0.5609255433082581,
      "learning_rate": 9.923035238284278e-06,
      "loss": 0.1704,
      "step": 4790
    },
    {
      "epoch": 1.5554115359688918,
      "grad_norm": 0.5831847190856934,
      "learning_rate": 9.888052488816862e-06,
      "loss": 0.1666,
      "step": 4800
    },
    {
      "epoch": 1.558651976668827,
      "grad_norm": 0.5986546874046326,
      "learning_rate": 9.853071109477219e-06,
      "loss": 0.1696,
      "step": 4810
    },
    {
      "epoch": 1.561892417368762,
      "grad_norm": 0.5974957346916199,
      "learning_rate": 9.818091528403148e-06,
      "loss": 0.1693,
      "step": 4820
    },
    {
      "epoch": 1.5651328580686974,
      "grad_norm": 0.5294414162635803,
      "learning_rate": 9.78311417371042e-06,
      "loss": 0.1726,
      "step": 4830
    },
    {
      "epoch": 1.5683732987686325,
      "grad_norm": 0.5616016387939453,
      "learning_rate": 9.748139473487563e-06,
      "loss": 0.1689,
      "step": 4840
    },
    {
      "epoch": 1.5716137394685679,
      "grad_norm": 0.509312629699707,
      "learning_rate": 9.713167855790618e-06,
      "loss": 0.1712,
      "step": 4850
    },
    {
      "epoch": 1.574854180168503,
      "grad_norm": 0.539430558681488,
      "learning_rate": 9.678199748637896e-06,
      "loss": 0.1702,
      "step": 4860
    },
    {
      "epoch": 1.578094620868438,
      "grad_norm": 0.553330659866333,
      "learning_rate": 9.643235580004749e-06,
      "loss": 0.1702,
      "step": 4870
    },
    {
      "epoch": 1.5813350615683732,
      "grad_norm": 0.5515002608299255,
      "learning_rate": 9.608275777818318e-06,
      "loss": 0.1699,
      "step": 4880
    },
    {
      "epoch": 1.5845755022683083,
      "grad_norm": 0.568331241607666,
      "learning_rate": 9.573320769952307e-06,
      "loss": 0.1675,
      "step": 4890
    },
    {
      "epoch": 1.5878159429682437,
      "grad_norm": 0.616708517074585,
      "learning_rate": 9.538370984221745e-06,
      "loss": 0.1743,
      "step": 4900
    },
    {
      "epoch": 1.591056383668179,
      "grad_norm": 0.5645186305046082,
      "learning_rate": 9.503426848377738e-06,
      "loss": 0.1685,
      "step": 4910
    },
    {
      "epoch": 1.5942968243681142,
      "grad_norm": 0.5398984551429749,
      "learning_rate": 9.468488790102246e-06,
      "loss": 0.1694,
      "step": 4920
    },
    {
      "epoch": 1.5975372650680493,
      "grad_norm": 0.5703518390655518,
      "learning_rate": 9.433557237002857e-06,
      "loss": 0.172,
      "step": 4930
    },
    {
      "epoch": 1.6007777057679844,
      "grad_norm": 0.5730645656585693,
      "learning_rate": 9.398632616607528e-06,
      "loss": 0.1674,
      "step": 4940
    },
    {
      "epoch": 1.6040181464679195,
      "grad_norm": 0.545231282711029,
      "learning_rate": 9.36371535635937e-06,
      "loss": 0.1693,
      "step": 4950
    },
    {
      "epoch": 1.6072585871678549,
      "grad_norm": 0.534635603427887,
      "learning_rate": 9.328805883611418e-06,
      "loss": 0.1742,
      "step": 4960
    },
    {
      "epoch": 1.61049902786779,
      "grad_norm": 0.5615566372871399,
      "learning_rate": 9.293904625621388e-06,
      "loss": 0.17,
      "step": 4970
    },
    {
      "epoch": 1.6137394685677253,
      "grad_norm": 0.5528943538665771,
      "learning_rate": 9.259012009546454e-06,
      "loss": 0.1728,
      "step": 4980
    },
    {
      "epoch": 1.6169799092676604,
      "grad_norm": 0.5567358136177063,
      "learning_rate": 9.224128462438043e-06,
      "loss": 0.1681,
      "step": 4990
    },
    {
      "epoch": 1.6202203499675956,
      "grad_norm": 0.5928312540054321,
      "learning_rate": 9.18925441123656e-06,
      "loss": 0.1673,
      "step": 5000
    },
    {
      "epoch": 1.6234607906675307,
      "grad_norm": 0.5878478288650513,
      "learning_rate": 9.154390282766202e-06,
      "loss": 0.1709,
      "step": 5010
    },
    {
      "epoch": 1.626701231367466,
      "grad_norm": 0.5694789290428162,
      "learning_rate": 9.11953650372972e-06,
      "loss": 0.1736,
      "step": 5020
    },
    {
      "epoch": 1.6299416720674011,
      "grad_norm": 0.5837799906730652,
      "learning_rate": 9.084693500703193e-06,
      "loss": 0.1673,
      "step": 5030
    },
    {
      "epoch": 1.6331821127673365,
      "grad_norm": 0.5467098951339722,
      "learning_rate": 9.049861700130822e-06,
      "loss": 0.1717,
      "step": 5040
    },
    {
      "epoch": 1.6364225534672716,
      "grad_norm": 0.5456043481826782,
      "learning_rate": 9.015041528319696e-06,
      "loss": 0.1714,
      "step": 5050
    },
    {
      "epoch": 1.6396629941672067,
      "grad_norm": 0.5332639217376709,
      "learning_rate": 8.980233411434575e-06,
      "loss": 0.1734,
      "step": 5060
    },
    {
      "epoch": 1.6429034348671419,
      "grad_norm": 0.558494508266449,
      "learning_rate": 8.945437775492687e-06,
      "loss": 0.1734,
      "step": 5070
    },
    {
      "epoch": 1.646143875567077,
      "grad_norm": 0.573129415512085,
      "learning_rate": 8.9106550463585e-06,
      "loss": 0.1707,
      "step": 5080
    },
    {
      "epoch": 1.6493843162670123,
      "grad_norm": 0.557108998298645,
      "learning_rate": 8.875885649738513e-06,
      "loss": 0.173,
      "step": 5090
    },
    {
      "epoch": 1.6526247569669477,
      "grad_norm": 0.5584518313407898,
      "learning_rate": 8.841130011176057e-06,
      "loss": 0.1657,
      "step": 5100
    },
    {
      "epoch": 1.6558651976668828,
      "grad_norm": 0.6053274273872375,
      "learning_rate": 8.806388556046069e-06,
      "loss": 0.1705,
      "step": 5110
    },
    {
      "epoch": 1.659105638366818,
      "grad_norm": 0.561824381351471,
      "learning_rate": 8.7716617095499e-06,
      "loss": 0.1738,
      "step": 5120
    },
    {
      "epoch": 1.662346079066753,
      "grad_norm": 0.5770959258079529,
      "learning_rate": 8.736949896710105e-06,
      "loss": 0.1664,
      "step": 5130
    },
    {
      "epoch": 1.6655865197666881,
      "grad_norm": 0.6200001239776611,
      "learning_rate": 8.702253542365235e-06,
      "loss": 0.168,
      "step": 5140
    },
    {
      "epoch": 1.6688269604666235,
      "grad_norm": 0.5707658529281616,
      "learning_rate": 8.66757307116465e-06,
      "loss": 0.1717,
      "step": 5150
    },
    {
      "epoch": 1.6720674011665586,
      "grad_norm": 0.5230342149734497,
      "learning_rate": 8.632908907563323e-06,
      "loss": 0.1698,
      "step": 5160
    },
    {
      "epoch": 1.675307841866494,
      "grad_norm": 0.5673912167549133,
      "learning_rate": 8.598261475816625e-06,
      "loss": 0.1684,
      "step": 5170
    },
    {
      "epoch": 1.678548282566429,
      "grad_norm": 0.5530970096588135,
      "learning_rate": 8.563631199975153e-06,
      "loss": 0.1724,
      "step": 5180
    },
    {
      "epoch": 1.6817887232663642,
      "grad_norm": 0.5472121834754944,
      "learning_rate": 8.52901850387953e-06,
      "loss": 0.1685,
      "step": 5190
    },
    {
      "epoch": 1.6850291639662993,
      "grad_norm": 0.5700592398643494,
      "learning_rate": 8.494423811155218e-06,
      "loss": 0.1626,
      "step": 5200
    },
    {
      "epoch": 1.6882696046662347,
      "grad_norm": 0.5841555595397949,
      "learning_rate": 8.45984754520734e-06,
      "loss": 0.1669,
      "step": 5210
    },
    {
      "epoch": 1.6915100453661698,
      "grad_norm": 0.5788343548774719,
      "learning_rate": 8.425290129215498e-06,
      "loss": 0.1684,
      "step": 5220
    },
    {
      "epoch": 1.6947504860661051,
      "grad_norm": 0.5441665649414062,
      "learning_rate": 8.390751986128571e-06,
      "loss": 0.1695,
      "step": 5230
    },
    {
      "epoch": 1.6979909267660402,
      "grad_norm": 0.5596961379051208,
      "learning_rate": 8.356233538659578e-06,
      "loss": 0.1674,
      "step": 5240
    },
    {
      "epoch": 1.7012313674659754,
      "grad_norm": 0.5396531224250793,
      "learning_rate": 8.321735209280468e-06,
      "loss": 0.168,
      "step": 5250
    },
    {
      "epoch": 1.7044718081659105,
      "grad_norm": 0.521856963634491,
      "learning_rate": 8.287257420216967e-06,
      "loss": 0.169,
      "step": 5260
    },
    {
      "epoch": 1.7077122488658456,
      "grad_norm": 0.5822368264198303,
      "learning_rate": 8.252800593443417e-06,
      "loss": 0.1683,
      "step": 5270
    },
    {
      "epoch": 1.710952689565781,
      "grad_norm": 0.5720469951629639,
      "learning_rate": 8.218365150677592e-06,
      "loss": 0.1745,
      "step": 5280
    },
    {
      "epoch": 1.7141931302657163,
      "grad_norm": 0.5264974236488342,
      "learning_rate": 8.183951513375547e-06,
      "loss": 0.1718,
      "step": 5290
    },
    {
      "epoch": 1.7174335709656514,
      "grad_norm": 0.5247780084609985,
      "learning_rate": 8.149560102726466e-06,
      "loss": 0.1687,
      "step": 5300
    },
    {
      "epoch": 1.7206740116655865,
      "grad_norm": 0.557797908782959,
      "learning_rate": 8.115191339647495e-06,
      "loss": 0.1657,
      "step": 5310
    },
    {
      "epoch": 1.7239144523655217,
      "grad_norm": 0.5767460465431213,
      "learning_rate": 8.080845644778593e-06,
      "loss": 0.1648,
      "step": 5320
    },
    {
      "epoch": 1.7271548930654568,
      "grad_norm": 0.5623366236686707,
      "learning_rate": 8.046523438477401e-06,
      "loss": 0.1691,
      "step": 5330
    },
    {
      "epoch": 1.7303953337653921,
      "grad_norm": 0.5495660901069641,
      "learning_rate": 8.01222514081407e-06,
      "loss": 0.1693,
      "step": 5340
    },
    {
      "epoch": 1.7336357744653272,
      "grad_norm": 0.5639829039573669,
      "learning_rate": 7.977951171566135e-06,
      "loss": 0.1742,
      "step": 5350
    },
    {
      "epoch": 1.7368762151652626,
      "grad_norm": 0.5484291911125183,
      "learning_rate": 7.943701950213374e-06,
      "loss": 0.1683,
      "step": 5360
    },
    {
      "epoch": 1.7401166558651977,
      "grad_norm": 0.5783697962760925,
      "learning_rate": 7.909477895932681e-06,
      "loss": 0.1687,
      "step": 5370
    },
    {
      "epoch": 1.7433570965651328,
      "grad_norm": 0.5929247140884399,
      "learning_rate": 7.875279427592926e-06,
      "loss": 0.1712,
      "step": 5380
    },
    {
      "epoch": 1.746597537265068,
      "grad_norm": 0.630285918712616,
      "learning_rate": 7.841106963749832e-06,
      "loss": 0.1681,
      "step": 5390
    },
    {
      "epoch": 1.7498379779650033,
      "grad_norm": 0.5437172651290894,
      "learning_rate": 7.806960922640848e-06,
      "loss": 0.1664,
      "step": 5400
    },
    {
      "epoch": 1.7530784186649384,
      "grad_norm": 0.5545098185539246,
      "learning_rate": 7.772841722180047e-06,
      "loss": 0.1678,
      "step": 5410
    },
    {
      "epoch": 1.7563188593648738,
      "grad_norm": 0.5582624077796936,
      "learning_rate": 7.738749779952986e-06,
      "loss": 0.1719,
      "step": 5420
    },
    {
      "epoch": 1.7595593000648089,
      "grad_norm": 0.5727649331092834,
      "learning_rate": 7.70468551321161e-06,
      "loss": 0.17,
      "step": 5430
    },
    {
      "epoch": 1.762799740764744,
      "grad_norm": 0.5902621746063232,
      "learning_rate": 7.670649338869154e-06,
      "loss": 0.1715,
      "step": 5440
    },
    {
      "epoch": 1.7660401814646791,
      "grad_norm": 0.5543310046195984,
      "learning_rate": 7.636641673495018e-06,
      "loss": 0.1665,
      "step": 5450
    },
    {
      "epoch": 1.7692806221646142,
      "grad_norm": 0.5816124677658081,
      "learning_rate": 7.602662933309684e-06,
      "loss": 0.1738,
      "step": 5460
    },
    {
      "epoch": 1.7725210628645496,
      "grad_norm": 0.5724789500236511,
      "learning_rate": 7.568713534179617e-06,
      "loss": 0.166,
      "step": 5470
    },
    {
      "epoch": 1.775761503564485,
      "grad_norm": 0.5352768301963806,
      "learning_rate": 7.53479389161218e-06,
      "loss": 0.1697,
      "step": 5480
    },
    {
      "epoch": 1.77900194426442,
      "grad_norm": 0.6213529706001282,
      "learning_rate": 7.500904420750535e-06,
      "loss": 0.167,
      "step": 5490
    },
    {
      "epoch": 1.7822423849643552,
      "grad_norm": 0.5516494512557983,
      "learning_rate": 7.467045536368588e-06,
      "loss": 0.1695,
      "step": 5500
    },
    {
      "epoch": 1.7854828256642903,
      "grad_norm": 0.5407071709632874,
      "learning_rate": 7.433217652865884e-06,
      "loss": 0.1677,
      "step": 5510
    },
    {
      "epoch": 1.7887232663642254,
      "grad_norm": 0.5824769139289856,
      "learning_rate": 7.399421184262551e-06,
      "loss": 0.1737,
      "step": 5520
    },
    {
      "epoch": 1.7919637070641607,
      "grad_norm": 0.5336689352989197,
      "learning_rate": 7.365656544194226e-06,
      "loss": 0.1712,
      "step": 5530
    },
    {
      "epoch": 1.7952041477640959,
      "grad_norm": 0.56043541431427,
      "learning_rate": 7.3319241459070044e-06,
      "loss": 0.1663,
      "step": 5540
    },
    {
      "epoch": 1.7984445884640312,
      "grad_norm": 0.5487886667251587,
      "learning_rate": 7.2982244022523685e-06,
      "loss": 0.1658,
      "step": 5550
    },
    {
      "epoch": 1.8016850291639663,
      "grad_norm": 0.5643541216850281,
      "learning_rate": 7.264557725682137e-06,
      "loss": 0.1697,
      "step": 5560
    },
    {
      "epoch": 1.8049254698639015,
      "grad_norm": 0.5663674473762512,
      "learning_rate": 7.2309245282434285e-06,
      "loss": 0.1649,
      "step": 5570
    },
    {
      "epoch": 1.8081659105638366,
      "grad_norm": 0.5643357038497925,
      "learning_rate": 7.197325221573599e-06,
      "loss": 0.1702,
      "step": 5580
    },
    {
      "epoch": 1.811406351263772,
      "grad_norm": 0.5671315789222717,
      "learning_rate": 7.163760216895224e-06,
      "loss": 0.1684,
      "step": 5590
    },
    {
      "epoch": 1.814646791963707,
      "grad_norm": 0.5991738438606262,
      "learning_rate": 7.130229925011047e-06,
      "loss": 0.167,
      "step": 5600
    },
    {
      "epoch": 1.8178872326636424,
      "grad_norm": 0.5863364934921265,
      "learning_rate": 7.096734756298975e-06,
      "loss": 0.1636,
      "step": 5610
    },
    {
      "epoch": 1.8211276733635775,
      "grad_norm": 0.6316577792167664,
      "learning_rate": 7.063275120707027e-06,
      "loss": 0.1667,
      "step": 5620
    },
    {
      "epoch": 1.8243681140635126,
      "grad_norm": 0.6006028652191162,
      "learning_rate": 7.029851427748342e-06,
      "loss": 0.1665,
      "step": 5630
    },
    {
      "epoch": 1.8276085547634477,
      "grad_norm": 0.5786643624305725,
      "learning_rate": 6.996464086496147e-06,
      "loss": 0.1691,
      "step": 5640
    },
    {
      "epoch": 1.8308489954633829,
      "grad_norm": 0.647168755531311,
      "learning_rate": 6.9631135055787645e-06,
      "loss": 0.1709,
      "step": 5650
    },
    {
      "epoch": 1.8340894361633182,
      "grad_norm": 0.5556980967521667,
      "learning_rate": 6.9298000931746145e-06,
      "loss": 0.1736,
      "step": 5660
    },
    {
      "epoch": 1.8373298768632536,
      "grad_norm": 0.6698198914527893,
      "learning_rate": 6.896524257007199e-06,
      "loss": 0.1666,
      "step": 5670
    },
    {
      "epoch": 1.8405703175631887,
      "grad_norm": 0.5966703295707703,
      "learning_rate": 6.863286404340127e-06,
      "loss": 0.1692,
      "step": 5680
    },
    {
      "epoch": 1.8438107582631238,
      "grad_norm": 0.5612844228744507,
      "learning_rate": 6.8300869419721296e-06,
      "loss": 0.1688,
      "step": 5690
    },
    {
      "epoch": 1.847051198963059,
      "grad_norm": 0.5898463129997253,
      "learning_rate": 6.796926276232071e-06,
      "loss": 0.1659,
      "step": 5700
    },
    {
      "epoch": 1.850291639662994,
      "grad_norm": 0.5727248191833496,
      "learning_rate": 6.7638048129739935e-06,
      "loss": 0.1659,
      "step": 5710
    },
    {
      "epoch": 1.8535320803629294,
      "grad_norm": 0.6000518798828125,
      "learning_rate": 6.7307229575721334e-06,
      "loss": 0.1703,
      "step": 5720
    },
    {
      "epoch": 1.8567725210628645,
      "grad_norm": 0.5474104285240173,
      "learning_rate": 6.697681114915964e-06,
      "loss": 0.1669,
      "step": 5730
    },
    {
      "epoch": 1.8600129617627998,
      "grad_norm": 0.5743942856788635,
      "learning_rate": 6.664679689405247e-06,
      "loss": 0.1719,
      "step": 5740
    },
    {
      "epoch": 1.863253402462735,
      "grad_norm": 0.6150799989700317,
      "learning_rate": 6.631719084945074e-06,
      "loss": 0.1677,
      "step": 5750
    },
    {
      "epoch": 1.86649384316267,
      "grad_norm": 0.5910884141921997,
      "learning_rate": 6.598799704940928e-06,
      "loss": 0.1664,
      "step": 5760
    },
    {
      "epoch": 1.8697342838626052,
      "grad_norm": 0.5662891268730164,
      "learning_rate": 6.56592195229374e-06,
      "loss": 0.166,
      "step": 5770
    },
    {
      "epoch": 1.8729747245625405,
      "grad_norm": 0.5656118392944336,
      "learning_rate": 6.533086229394976e-06,
      "loss": 0.1722,
      "step": 5780
    },
    {
      "epoch": 1.8762151652624757,
      "grad_norm": 0.5573721528053284,
      "learning_rate": 6.500292938121688e-06,
      "loss": 0.1711,
      "step": 5790
    },
    {
      "epoch": 1.879455605962411,
      "grad_norm": 0.5635893940925598,
      "learning_rate": 6.46754247983161e-06,
      "loss": 0.1669,
      "step": 5800
    },
    {
      "epoch": 1.8826960466623461,
      "grad_norm": 0.569210946559906,
      "learning_rate": 6.434835255358239e-06,
      "loss": 0.1644,
      "step": 5810
    },
    {
      "epoch": 1.8859364873622813,
      "grad_norm": 0.5874742865562439,
      "learning_rate": 6.402171665005934e-06,
      "loss": 0.1674,
      "step": 5820
    },
    {
      "epoch": 1.8891769280622164,
      "grad_norm": 0.612249493598938,
      "learning_rate": 6.369552108545024e-06,
      "loss": 0.17,
      "step": 5830
    },
    {
      "epoch": 1.8924173687621515,
      "grad_norm": 0.5598555207252502,
      "learning_rate": 6.336976985206894e-06,
      "loss": 0.1704,
      "step": 5840
    },
    {
      "epoch": 1.8956578094620868,
      "grad_norm": 0.5456566214561462,
      "learning_rate": 6.304446693679116e-06,
      "loss": 0.1724,
      "step": 5850
    },
    {
      "epoch": 1.8988982501620222,
      "grad_norm": 0.5558242797851562,
      "learning_rate": 6.271961632100566e-06,
      "loss": 0.1638,
      "step": 5860
    },
    {
      "epoch": 1.9021386908619573,
      "grad_norm": 0.5916482210159302,
      "learning_rate": 6.239522198056545e-06,
      "loss": 0.1708,
      "step": 5870
    },
    {
      "epoch": 1.9053791315618924,
      "grad_norm": 0.5311204195022583,
      "learning_rate": 6.207128788573922e-06,
      "loss": 0.1673,
      "step": 5880
    },
    {
      "epoch": 1.9086195722618275,
      "grad_norm": 0.6390945911407471,
      "learning_rate": 6.174781800116274e-06,
      "loss": 0.1705,
      "step": 5890
    },
    {
      "epoch": 1.9118600129617627,
      "grad_norm": 0.5906262993812561,
      "learning_rate": 6.14248162857902e-06,
      "loss": 0.168,
      "step": 5900
    },
    {
      "epoch": 1.915100453661698,
      "grad_norm": 0.5333272218704224,
      "learning_rate": 6.110228669284595e-06,
      "loss": 0.1675,
      "step": 5910
    },
    {
      "epoch": 1.9183408943616331,
      "grad_norm": 0.5796603560447693,
      "learning_rate": 6.078023316977598e-06,
      "loss": 0.1669,
      "step": 5920
    },
    {
      "epoch": 1.9215813350615685,
      "grad_norm": 0.5544694066047668,
      "learning_rate": 6.045865965819961e-06,
      "loss": 0.1691,
      "step": 5930
    },
    {
      "epoch": 1.9248217757615036,
      "grad_norm": 0.6070683598518372,
      "learning_rate": 6.0137570093861455e-06,
      "loss": 0.1721,
      "step": 5940
    },
    {
      "epoch": 1.9280622164614387,
      "grad_norm": 0.5431628823280334,
      "learning_rate": 5.981696840658289e-06,
      "loss": 0.1666,
      "step": 5950
    },
    {
      "epoch": 1.9313026571613738,
      "grad_norm": 0.5597094893455505,
      "learning_rate": 5.949685852021425e-06,
      "loss": 0.1637,
      "step": 5960
    },
    {
      "epoch": 1.9345430978613092,
      "grad_norm": 0.5714221596717834,
      "learning_rate": 5.917724435258672e-06,
      "loss": 0.167,
      "step": 5970
    },
    {
      "epoch": 1.9377835385612443,
      "grad_norm": 0.5589957237243652,
      "learning_rate": 5.885812981546434e-06,
      "loss": 0.1688,
      "step": 5980
    },
    {
      "epoch": 1.9410239792611796,
      "grad_norm": 0.5911544561386108,
      "learning_rate": 5.853951881449611e-06,
      "loss": 0.1637,
      "step": 5990
    },
    {
      "epoch": 1.9442644199611148,
      "grad_norm": 0.598724365234375,
      "learning_rate": 5.822141524916842e-06,
      "loss": 0.1701,
      "step": 6000
    },
    {
      "epoch": 1.9475048606610499,
      "grad_norm": 0.5870089530944824,
      "learning_rate": 5.790382301275696e-06,
      "loss": 0.1697,
      "step": 6010
    },
    {
      "epoch": 1.950745301360985,
      "grad_norm": 0.5618594884872437,
      "learning_rate": 5.758674599227938e-06,
      "loss": 0.1666,
      "step": 6020
    },
    {
      "epoch": 1.9539857420609201,
      "grad_norm": 0.5852800607681274,
      "learning_rate": 5.727018806844746e-06,
      "loss": 0.163,
      "step": 6030
    },
    {
      "epoch": 1.9572261827608555,
      "grad_norm": 0.5577788949012756,
      "learning_rate": 5.695415311561989e-06,
      "loss": 0.1673,
      "step": 6040
    },
    {
      "epoch": 1.9604666234607908,
      "grad_norm": 0.5675128698348999,
      "learning_rate": 5.663864500175456e-06,
      "loss": 0.1692,
      "step": 6050
    },
    {
      "epoch": 1.963707064160726,
      "grad_norm": 0.6040117740631104,
      "learning_rate": 5.632366758836157e-06,
      "loss": 0.17,
      "step": 6060
    },
    {
      "epoch": 1.966947504860661,
      "grad_norm": 0.5758216977119446,
      "learning_rate": 5.600922473045554e-06,
      "loss": 0.1635,
      "step": 6070
    },
    {
      "epoch": 1.9701879455605962,
      "grad_norm": 0.5782884359359741,
      "learning_rate": 5.569532027650884e-06,
      "loss": 0.1656,
      "step": 6080
    },
    {
      "epoch": 1.9734283862605313,
      "grad_norm": 0.5895426869392395,
      "learning_rate": 5.538195806840414e-06,
      "loss": 0.1639,
      "step": 6090
    },
    {
      "epoch": 1.9766688269604666,
      "grad_norm": 0.5833635330200195,
      "learning_rate": 5.506914194138768e-06,
      "loss": 0.1683,
      "step": 6100
    },
    {
      "epoch": 1.9799092676604018,
      "grad_norm": 0.6033540368080139,
      "learning_rate": 5.475687572402217e-06,
      "loss": 0.1669,
      "step": 6110
    },
    {
      "epoch": 1.983149708360337,
      "grad_norm": 0.5996755361557007,
      "learning_rate": 5.444516323813999e-06,
      "loss": 0.1672,
      "step": 6120
    },
    {
      "epoch": 1.9863901490602722,
      "grad_norm": 0.5930240750312805,
      "learning_rate": 5.413400829879626e-06,
      "loss": 0.1699,
      "step": 6130
    },
    {
      "epoch": 1.9896305897602073,
      "grad_norm": 0.5818130373954773,
      "learning_rate": 5.382341471422242e-06,
      "loss": 0.1652,
      "step": 6140
    },
    {
      "epoch": 1.9928710304601425,
      "grad_norm": 0.5329946279525757,
      "learning_rate": 5.3513386285779465e-06,
      "loss": 0.1657,
      "step": 6150
    },
    {
      "epoch": 1.9961114711600778,
      "grad_norm": 0.5744707584381104,
      "learning_rate": 5.3203926807911335e-06,
      "loss": 0.1667,
      "step": 6160
    },
    {
      "epoch": 1.999351911860013,
      "grad_norm": 0.6170487403869629,
      "learning_rate": 5.2895040068098646e-06,
      "loss": 0.1674,
      "step": 6170
    },
    {
      "epoch": 2.0025923525599483,
      "grad_norm": 0.5679187178611755,
      "learning_rate": 5.2586729846812275e-06,
      "loss": 0.1604,
      "step": 6180
    },
    {
      "epoch": 2.0058327932598834,
      "grad_norm": 0.5964841842651367,
      "learning_rate": 5.227899991746708e-06,
      "loss": 0.1617,
      "step": 6190
    },
    {
      "epoch": 2.0090732339598185,
      "grad_norm": 0.5954318642616272,
      "learning_rate": 5.197185404637562e-06,
      "loss": 0.1641,
      "step": 6200
    },
    {
      "epoch": 2.0123136746597536,
      "grad_norm": 0.5662029385566711,
      "learning_rate": 5.166529599270228e-06,
      "loss": 0.1621,
      "step": 6210
    },
    {
      "epoch": 2.0155541153596888,
      "grad_norm": 0.5646767616271973,
      "learning_rate": 5.135932950841698e-06,
      "loss": 0.1666,
      "step": 6220
    },
    {
      "epoch": 2.0187945560596243,
      "grad_norm": 0.6184542179107666,
      "learning_rate": 5.105395833824964e-06,
      "loss": 0.1659,
      "step": 6230
    },
    {
      "epoch": 2.0220349967595594,
      "grad_norm": 0.5534775257110596,
      "learning_rate": 5.074918621964391e-06,
      "loss": 0.1637,
      "step": 6240
    },
    {
      "epoch": 2.0252754374594946,
      "grad_norm": 0.5617857575416565,
      "learning_rate": 5.044501688271175e-06,
      "loss": 0.1655,
      "step": 6250
    },
    {
      "epoch": 2.0285158781594297,
      "grad_norm": 0.5340557098388672,
      "learning_rate": 5.014145405018757e-06,
      "loss": 0.1567,
      "step": 6260
    },
    {
      "epoch": 2.031756318859365,
      "grad_norm": 0.6102846264839172,
      "learning_rate": 4.983850143738285e-06,
      "loss": 0.1672,
      "step": 6270
    },
    {
      "epoch": 2.0349967595593,
      "grad_norm": 0.6112416982650757,
      "learning_rate": 4.953616275214054e-06,
      "loss": 0.1669,
      "step": 6280
    },
    {
      "epoch": 2.038237200259235,
      "grad_norm": 0.6174356937408447,
      "learning_rate": 4.923444169478978e-06,
      "loss": 0.1617,
      "step": 6290
    },
    {
      "epoch": 2.0414776409591706,
      "grad_norm": 0.5842755436897278,
      "learning_rate": 4.89333419581004e-06,
      "loss": 0.1638,
      "step": 6300
    },
    {
      "epoch": 2.0447180816591057,
      "grad_norm": 0.5650213360786438,
      "learning_rate": 4.863286722723802e-06,
      "loss": 0.1622,
      "step": 6310
    },
    {
      "epoch": 2.047958522359041,
      "grad_norm": 0.5896313786506653,
      "learning_rate": 4.833302117971879e-06,
      "loss": 0.1627,
      "step": 6320
    },
    {
      "epoch": 2.051198963058976,
      "grad_norm": 0.5962388515472412,
      "learning_rate": 4.803380748536422e-06,
      "loss": 0.1655,
      "step": 6330
    },
    {
      "epoch": 2.054439403758911,
      "grad_norm": 0.5873481035232544,
      "learning_rate": 4.7735229806256745e-06,
      "loss": 0.1619,
      "step": 6340
    },
    {
      "epoch": 2.057679844458846,
      "grad_norm": 0.620989978313446,
      "learning_rate": 4.743729179669429e-06,
      "loss": 0.163,
      "step": 6350
    },
    {
      "epoch": 2.060920285158782,
      "grad_norm": 0.5813350677490234,
      "learning_rate": 4.713999710314606e-06,
      "loss": 0.1616,
      "step": 6360
    },
    {
      "epoch": 2.064160725858717,
      "grad_norm": 0.6147864460945129,
      "learning_rate": 4.684334936420757e-06,
      "loss": 0.164,
      "step": 6370
    },
    {
      "epoch": 2.067401166558652,
      "grad_norm": 0.6104962825775146,
      "learning_rate": 4.6547352210556325e-06,
      "loss": 0.157,
      "step": 6380
    },
    {
      "epoch": 2.070641607258587,
      "grad_norm": 0.5644301772117615,
      "learning_rate": 4.625200926490728e-06,
      "loss": 0.1638,
      "step": 6390
    },
    {
      "epoch": 2.0738820479585223,
      "grad_norm": 0.5647985339164734,
      "learning_rate": 4.595732414196856e-06,
      "loss": 0.164,
      "step": 6400
    },
    {
      "epoch": 2.0771224886584574,
      "grad_norm": 0.6184242963790894,
      "learning_rate": 4.5663300448397094e-06,
      "loss": 0.1658,
      "step": 6410
    },
    {
      "epoch": 2.080362929358393,
      "grad_norm": 0.6357368230819702,
      "learning_rate": 4.536994178275468e-06,
      "loss": 0.164,
      "step": 6420
    },
    {
      "epoch": 2.083603370058328,
      "grad_norm": 0.6048440933227539,
      "learning_rate": 4.507725173546368e-06,
      "loss": 0.1627,
      "step": 6430
    },
    {
      "epoch": 2.086843810758263,
      "grad_norm": 0.5608782172203064,
      "learning_rate": 4.478523388876338e-06,
      "loss": 0.1633,
      "step": 6440
    },
    {
      "epoch": 2.0900842514581983,
      "grad_norm": 0.5611481070518494,
      "learning_rate": 4.449389181666589e-06,
      "loss": 0.1591,
      "step": 6450
    },
    {
      "epoch": 2.0933246921581334,
      "grad_norm": 0.5933445692062378,
      "learning_rate": 4.420322908491258e-06,
      "loss": 0.1589,
      "step": 6460
    },
    {
      "epoch": 2.0965651328580686,
      "grad_norm": 0.6066709160804749,
      "learning_rate": 4.391324925093025e-06,
      "loss": 0.164,
      "step": 6470
    },
    {
      "epoch": 2.0998055735580037,
      "grad_norm": 0.6246383190155029,
      "learning_rate": 4.362395586378777e-06,
      "loss": 0.1604,
      "step": 6480
    },
    {
      "epoch": 2.1030460142579392,
      "grad_norm": 0.6036426424980164,
      "learning_rate": 4.333535246415262e-06,
      "loss": 0.1612,
      "step": 6490
    },
    {
      "epoch": 2.1062864549578744,
      "grad_norm": 0.6577867269515991,
      "learning_rate": 4.304744258424735e-06,
      "loss": 0.1595,
      "step": 6500
    },
    {
      "epoch": 2.1095268956578095,
      "grad_norm": 0.6396222114562988,
      "learning_rate": 4.2760229747806755e-06,
      "loss": 0.1623,
      "step": 6510
    },
    {
      "epoch": 2.1127673363577446,
      "grad_norm": 0.5878869295120239,
      "learning_rate": 4.247371747003426e-06,
      "loss": 0.161,
      "step": 6520
    },
    {
      "epoch": 2.1160077770576797,
      "grad_norm": 0.6427369713783264,
      "learning_rate": 4.218790925755929e-06,
      "loss": 0.1633,
      "step": 6530
    },
    {
      "epoch": 2.119248217757615,
      "grad_norm": 0.5528991222381592,
      "learning_rate": 4.190280860839409e-06,
      "loss": 0.1672,
      "step": 6540
    },
    {
      "epoch": 2.1224886584575504,
      "grad_norm": 0.587990939617157,
      "learning_rate": 4.161841901189112e-06,
      "loss": 0.1693,
      "step": 6550
    },
    {
      "epoch": 2.1257290991574855,
      "grad_norm": 0.5496055483818054,
      "learning_rate": 4.133474394870021e-06,
      "loss": 0.1604,
      "step": 6560
    },
    {
      "epoch": 2.1289695398574207,
      "grad_norm": 0.6124466061592102,
      "learning_rate": 4.105178689072605e-06,
      "loss": 0.1615,
      "step": 6570
    },
    {
      "epoch": 2.1322099805573558,
      "grad_norm": 0.6090087294578552,
      "learning_rate": 4.076955130108554e-06,
      "loss": 0.1664,
      "step": 6580
    },
    {
      "epoch": 2.135450421257291,
      "grad_norm": 0.610451340675354,
      "learning_rate": 4.048804063406565e-06,
      "loss": 0.1594,
      "step": 6590
    },
    {
      "epoch": 2.138690861957226,
      "grad_norm": 0.606580376625061,
      "learning_rate": 4.020725833508088e-06,
      "loss": 0.1619,
      "step": 6600
    },
    {
      "epoch": 2.141931302657161,
      "grad_norm": 0.5834535956382751,
      "learning_rate": 3.992720784063131e-06,
      "loss": 0.1612,
      "step": 6610
    },
    {
      "epoch": 2.1451717433570967,
      "grad_norm": 0.6408776044845581,
      "learning_rate": 3.964789257826042e-06,
      "loss": 0.1603,
      "step": 6620
    },
    {
      "epoch": 2.148412184057032,
      "grad_norm": 0.6260830163955688,
      "learning_rate": 3.93693159665132e-06,
      "loss": 0.1662,
      "step": 6630
    },
    {
      "epoch": 2.151652624756967,
      "grad_norm": 0.6311634182929993,
      "learning_rate": 3.90914814148942e-06,
      "loss": 0.1663,
      "step": 6640
    },
    {
      "epoch": 2.154893065456902,
      "grad_norm": 0.6953462958335876,
      "learning_rate": 3.881439232382595e-06,
      "loss": 0.1643,
      "step": 6650
    },
    {
      "epoch": 2.158133506156837,
      "grad_norm": 0.594231367111206,
      "learning_rate": 3.853805208460728e-06,
      "loss": 0.163,
      "step": 6660
    },
    {
      "epoch": 2.1613739468567728,
      "grad_norm": 0.5703416466712952,
      "learning_rate": 3.826246407937176e-06,
      "loss": 0.1641,
      "step": 6670
    },
    {
      "epoch": 2.164614387556708,
      "grad_norm": 0.5840994715690613,
      "learning_rate": 3.7987631681046435e-06,
      "loss": 0.1628,
      "step": 6680
    },
    {
      "epoch": 2.167854828256643,
      "grad_norm": 0.6088452339172363,
      "learning_rate": 3.771355825331032e-06,
      "loss": 0.1596,
      "step": 6690
    },
    {
      "epoch": 2.171095268956578,
      "grad_norm": 0.5824825167655945,
      "learning_rate": 3.7440247150553532e-06,
      "loss": 0.1646,
      "step": 6700
    },
    {
      "epoch": 2.1743357096565132,
      "grad_norm": 0.5920184850692749,
      "learning_rate": 3.716770171783595e-06,
      "loss": 0.1611,
      "step": 6710
    },
    {
      "epoch": 2.1775761503564484,
      "grad_norm": 0.5921183228492737,
      "learning_rate": 3.6895925290846467e-06,
      "loss": 0.1576,
      "step": 6720
    },
    {
      "epoch": 2.1808165910563835,
      "grad_norm": 0.5582354664802551,
      "learning_rate": 3.6624921195862116e-06,
      "loss": 0.1683,
      "step": 6730
    },
    {
      "epoch": 2.184057031756319,
      "grad_norm": 0.6019490957260132,
      "learning_rate": 3.6354692749707344e-06,
      "loss": 0.1659,
      "step": 6740
    },
    {
      "epoch": 2.187297472456254,
      "grad_norm": 0.6315116882324219,
      "learning_rate": 3.608524325971331e-06,
      "loss": 0.1618,
      "step": 6750
    },
    {
      "epoch": 2.1905379131561893,
      "grad_norm": 0.5897891521453857,
      "learning_rate": 3.5816576023677687e-06,
      "loss": 0.1611,
      "step": 6760
    },
    {
      "epoch": 2.1937783538561244,
      "grad_norm": 0.6150364875793457,
      "learning_rate": 3.554869432982394e-06,
      "loss": 0.1606,
      "step": 6770
    },
    {
      "epoch": 2.1970187945560595,
      "grad_norm": 0.6012031435966492,
      "learning_rate": 3.5281601456761404e-06,
      "loss": 0.1685,
      "step": 6780
    },
    {
      "epoch": 2.2002592352559946,
      "grad_norm": 0.6207108497619629,
      "learning_rate": 3.5015300673444995e-06,
      "loss": 0.1648,
      "step": 6790
    },
    {
      "epoch": 2.20349967595593,
      "grad_norm": 0.6222384572029114,
      "learning_rate": 3.4749795239135197e-06,
      "loss": 0.1629,
      "step": 6800
    },
    {
      "epoch": 2.2067401166558653,
      "grad_norm": 0.5715846419334412,
      "learning_rate": 3.448508840335825e-06,
      "loss": 0.1668,
      "step": 6810
    },
    {
      "epoch": 2.2099805573558005,
      "grad_norm": 0.6227591037750244,
      "learning_rate": 3.4221183405866223e-06,
      "loss": 0.1637,
      "step": 6820
    },
    {
      "epoch": 2.2132209980557356,
      "grad_norm": 0.6437792778015137,
      "learning_rate": 3.395808347659759e-06,
      "loss": 0.1641,
      "step": 6830
    },
    {
      "epoch": 2.2164614387556707,
      "grad_norm": 0.567890465259552,
      "learning_rate": 3.3695791835637524e-06,
      "loss": 0.1624,
      "step": 6840
    },
    {
      "epoch": 2.219701879455606,
      "grad_norm": 0.6012344360351562,
      "learning_rate": 3.3434311693178588e-06,
      "loss": 0.1614,
      "step": 6850
    },
    {
      "epoch": 2.222942320155541,
      "grad_norm": 0.6230034232139587,
      "learning_rate": 3.3173646249481308e-06,
      "loss": 0.1541,
      "step": 6860
    },
    {
      "epoch": 2.2261827608554765,
      "grad_norm": 0.6206398606300354,
      "learning_rate": 3.2913798694835187e-06,
      "loss": 0.161,
      "step": 6870
    },
    {
      "epoch": 2.2294232015554116,
      "grad_norm": 0.6328881978988647,
      "learning_rate": 3.2654772209519493e-06,
      "loss": 0.165,
      "step": 6880
    },
    {
      "epoch": 2.2326636422553467,
      "grad_norm": 0.6193472743034363,
      "learning_rate": 3.239656996376447e-06,
      "loss": 0.1612,
      "step": 6890
    },
    {
      "epoch": 2.235904082955282,
      "grad_norm": 0.5644786357879639,
      "learning_rate": 3.213919511771245e-06,
      "loss": 0.1651,
      "step": 6900
    },
    {
      "epoch": 2.239144523655217,
      "grad_norm": 0.6122100353240967,
      "learning_rate": 3.1882650821379247e-06,
      "loss": 0.1585,
      "step": 6910
    },
    {
      "epoch": 2.242384964355152,
      "grad_norm": 0.5660824775695801,
      "learning_rate": 3.1626940214615466e-06,
      "loss": 0.1637,
      "step": 6920
    },
    {
      "epoch": 2.2456254050550877,
      "grad_norm": 0.6007344126701355,
      "learning_rate": 3.137206642706828e-06,
      "loss": 0.1656,
      "step": 6930
    },
    {
      "epoch": 2.248865845755023,
      "grad_norm": 0.6480769515037537,
      "learning_rate": 3.11180325781429e-06,
      "loss": 0.1676,
      "step": 6940
    },
    {
      "epoch": 2.252106286454958,
      "grad_norm": 0.5941105484962463,
      "learning_rate": 3.0864841776964615e-06,
      "loss": 0.1597,
      "step": 6950
    },
    {
      "epoch": 2.255346727154893,
      "grad_norm": 0.6000403165817261,
      "learning_rate": 3.061249712234058e-06,
      "loss": 0.1585,
      "step": 6960
    },
    {
      "epoch": 2.258587167854828,
      "grad_norm": 0.6292389631271362,
      "learning_rate": 3.0361001702721983e-06,
      "loss": 0.1694,
      "step": 6970
    },
    {
      "epoch": 2.2618276085547633,
      "grad_norm": 0.6100636720657349,
      "learning_rate": 3.011035859616619e-06,
      "loss": 0.1647,
      "step": 6980
    },
    {
      "epoch": 2.2650680492546984,
      "grad_norm": 0.5739380121231079,
      "learning_rate": 2.9860570870299045e-06,
      "loss": 0.1704,
      "step": 6990
    },
    {
      "epoch": 2.268308489954634,
      "grad_norm": 0.6085423827171326,
      "learning_rate": 2.961164158227743e-06,
      "loss": 0.1584,
      "step": 7000
    },
    {
      "epoch": 2.271548930654569,
      "grad_norm": 0.5612760782241821,
      "learning_rate": 2.9363573778751776e-06,
      "loss": 0.1646,
      "step": 7010
    },
    {
      "epoch": 2.274789371354504,
      "grad_norm": 0.6217619180679321,
      "learning_rate": 2.9116370495828817e-06,
      "loss": 0.1634,
      "step": 7020
    },
    {
      "epoch": 2.2780298120544393,
      "grad_norm": 0.6160673499107361,
      "learning_rate": 2.8870034759034306e-06,
      "loss": 0.163,
      "step": 7030
    },
    {
      "epoch": 2.2812702527543745,
      "grad_norm": 0.5880641937255859,
      "learning_rate": 2.862456958327622e-06,
      "loss": 0.1647,
      "step": 7040
    },
    {
      "epoch": 2.28451069345431,
      "grad_norm": 0.6190100312232971,
      "learning_rate": 2.837997797280756e-06,
      "loss": 0.1645,
      "step": 7050
    },
    {
      "epoch": 2.287751134154245,
      "grad_norm": 0.6364421844482422,
      "learning_rate": 2.8136262921189884e-06,
      "loss": 0.162,
      "step": 7060
    },
    {
      "epoch": 2.2909915748541803,
      "grad_norm": 0.6481665372848511,
      "learning_rate": 2.789342741125648e-06,
      "loss": 0.1618,
      "step": 7070
    },
    {
      "epoch": 2.2942320155541154,
      "grad_norm": 0.5884986519813538,
      "learning_rate": 2.7651474415075917e-06,
      "loss": 0.1595,
      "step": 7080
    },
    {
      "epoch": 2.2974724562540505,
      "grad_norm": 0.612907350063324,
      "learning_rate": 2.7410406893915607e-06,
      "loss": 0.164,
      "step": 7090
    },
    {
      "epoch": 2.3007128969539856,
      "grad_norm": 0.5904319286346436,
      "learning_rate": 2.7170227798205705e-06,
      "loss": 0.1596,
      "step": 7100
    },
    {
      "epoch": 2.3039533376539207,
      "grad_norm": 0.5739188194274902,
      "learning_rate": 2.6930940067502787e-06,
      "loss": 0.1649,
      "step": 7110
    },
    {
      "epoch": 2.3071937783538563,
      "grad_norm": 0.6538429856300354,
      "learning_rate": 2.6692546630454187e-06,
      "loss": 0.1644,
      "step": 7120
    },
    {
      "epoch": 2.3104342190537914,
      "grad_norm": 0.615489661693573,
      "learning_rate": 2.645505040476174e-06,
      "loss": 0.16,
      "step": 7130
    },
    {
      "epoch": 2.3136746597537265,
      "grad_norm": 0.6487880945205688,
      "learning_rate": 2.6218454297146455e-06,
      "loss": 0.1557,
      "step": 7140
    },
    {
      "epoch": 2.3169151004536617,
      "grad_norm": 0.6159577965736389,
      "learning_rate": 2.5982761203312733e-06,
      "loss": 0.1651,
      "step": 7150
    },
    {
      "epoch": 2.320155541153597,
      "grad_norm": 0.6175617575645447,
      "learning_rate": 2.5747974007912903e-06,
      "loss": 0.1647,
      "step": 7160
    },
    {
      "epoch": 2.323395981853532,
      "grad_norm": 0.6157281994819641,
      "learning_rate": 2.551409558451209e-06,
      "loss": 0.1653,
      "step": 7170
    },
    {
      "epoch": 2.3266364225534675,
      "grad_norm": 0.5770981907844543,
      "learning_rate": 2.5281128795552866e-06,
      "loss": 0.1564,
      "step": 7180
    },
    {
      "epoch": 2.3298768632534026,
      "grad_norm": 0.6166523694992065,
      "learning_rate": 2.504907649232038e-06,
      "loss": 0.1664,
      "step": 7190
    },
    {
      "epoch": 2.3331173039533377,
      "grad_norm": 0.6452524065971375,
      "learning_rate": 2.481794151490724e-06,
      "loss": 0.1619,
      "step": 7200
    },
    {
      "epoch": 2.336357744653273,
      "grad_norm": 0.5836117267608643,
      "learning_rate": 2.4587726692179004e-06,
      "loss": 0.1638,
      "step": 7210
    },
    {
      "epoch": 2.339598185353208,
      "grad_norm": 0.5710061192512512,
      "learning_rate": 2.435843484173934e-06,
      "loss": 0.162,
      "step": 7220
    },
    {
      "epoch": 2.342838626053143,
      "grad_norm": 0.5602462291717529,
      "learning_rate": 2.413006876989574e-06,
      "loss": 0.1641,
      "step": 7230
    },
    {
      "epoch": 2.346079066753078,
      "grad_norm": 0.5818106532096863,
      "learning_rate": 2.390263127162501e-06,
      "loss": 0.163,
      "step": 7240
    },
    {
      "epoch": 2.3493195074530138,
      "grad_norm": 0.6058637499809265,
      "learning_rate": 2.367612513053916e-06,
      "loss": 0.1666,
      "step": 7250
    },
    {
      "epoch": 2.352559948152949,
      "grad_norm": 0.5862388014793396,
      "learning_rate": 2.345055311885124e-06,
      "loss": 0.1624,
      "step": 7260
    },
    {
      "epoch": 2.355800388852884,
      "grad_norm": 0.6557866930961609,
      "learning_rate": 2.322591799734154e-06,
      "loss": 0.1625,
      "step": 7270
    },
    {
      "epoch": 2.359040829552819,
      "grad_norm": 0.6123170852661133,
      "learning_rate": 2.300222251532371e-06,
      "loss": 0.1611,
      "step": 7280
    },
    {
      "epoch": 2.3622812702527543,
      "grad_norm": 0.6764755845069885,
      "learning_rate": 2.2779469410611166e-06,
      "loss": 0.1585,
      "step": 7290
    },
    {
      "epoch": 2.3655217109526894,
      "grad_norm": 0.6807884573936462,
      "learning_rate": 2.2557661409483432e-06,
      "loss": 0.1621,
      "step": 7300
    },
    {
      "epoch": 2.368762151652625,
      "grad_norm": 0.6307289004325867,
      "learning_rate": 2.2336801226653037e-06,
      "loss": 0.1597,
      "step": 7310
    },
    {
      "epoch": 2.37200259235256,
      "grad_norm": 0.5583116412162781,
      "learning_rate": 2.211689156523208e-06,
      "loss": 0.1633,
      "step": 7320
    },
    {
      "epoch": 2.375243033052495,
      "grad_norm": 0.6138141751289368,
      "learning_rate": 2.1897935116699163e-06,
      "loss": 0.1641,
      "step": 7330
    },
    {
      "epoch": 2.3784834737524303,
      "grad_norm": 0.6267179250717163,
      "learning_rate": 2.167993456086659e-06,
      "loss": 0.1629,
      "step": 7340
    },
    {
      "epoch": 2.3817239144523654,
      "grad_norm": 0.6219374537467957,
      "learning_rate": 2.1462892565847404e-06,
      "loss": 0.1661,
      "step": 7350
    },
    {
      "epoch": 2.3849643551523005,
      "grad_norm": 0.5940848588943481,
      "learning_rate": 2.124681178802287e-06,
      "loss": 0.1641,
      "step": 7360
    },
    {
      "epoch": 2.3882047958522357,
      "grad_norm": 0.5908645391464233,
      "learning_rate": 2.103169487200979e-06,
      "loss": 0.164,
      "step": 7370
    },
    {
      "epoch": 2.3914452365521712,
      "grad_norm": 0.639104962348938,
      "learning_rate": 2.081754445062838e-06,
      "loss": 0.158,
      "step": 7380
    },
    {
      "epoch": 2.3946856772521063,
      "grad_norm": 0.6187145709991455,
      "learning_rate": 2.0604363144869732e-06,
      "loss": 0.1618,
      "step": 7390
    },
    {
      "epoch": 2.3979261179520415,
      "grad_norm": 0.6111841201782227,
      "learning_rate": 2.0392153563864157e-06,
      "loss": 0.1632,
      "step": 7400
    },
    {
      "epoch": 2.4011665586519766,
      "grad_norm": 0.646199643611908,
      "learning_rate": 2.0180918304848764e-06,
      "loss": 0.1605,
      "step": 7410
    },
    {
      "epoch": 2.4044069993519117,
      "grad_norm": 0.6001852750778198,
      "learning_rate": 1.9970659953136083e-06,
      "loss": 0.1626,
      "step": 7420
    },
    {
      "epoch": 2.4076474400518473,
      "grad_norm": 0.5756920576095581,
      "learning_rate": 1.9761381082082144e-06,
      "loss": 0.1609,
      "step": 7430
    },
    {
      "epoch": 2.4108878807517824,
      "grad_norm": 0.5995956063270569,
      "learning_rate": 1.9553084253055164e-06,
      "loss": 0.1589,
      "step": 7440
    },
    {
      "epoch": 2.4141283214517175,
      "grad_norm": 0.6164600849151611,
      "learning_rate": 1.934577201540412e-06,
      "loss": 0.1604,
      "step": 7450
    },
    {
      "epoch": 2.4173687621516526,
      "grad_norm": 0.6176742911338806,
      "learning_rate": 1.913944690642757e-06,
      "loss": 0.161,
      "step": 7460
    },
    {
      "epoch": 2.4206092028515878,
      "grad_norm": 0.6061776876449585,
      "learning_rate": 1.8934111451342497e-06,
      "loss": 0.1651,
      "step": 7470
    },
    {
      "epoch": 2.423849643551523,
      "grad_norm": 0.6157812476158142,
      "learning_rate": 1.8729768163253581e-06,
      "loss": 0.162,
      "step": 7480
    },
    {
      "epoch": 2.427090084251458,
      "grad_norm": 0.5737946629524231,
      "learning_rate": 1.8526419543122365e-06,
      "loss": 0.1602,
      "step": 7490
    },
    {
      "epoch": 2.4303305249513936,
      "grad_norm": 0.6338321566581726,
      "learning_rate": 1.8324068079736523e-06,
      "loss": 0.1602,
      "step": 7500
    },
    {
      "epoch": 2.4335709656513287,
      "grad_norm": 0.6152572631835938,
      "learning_rate": 1.8122716249679596e-06,
      "loss": 0.1652,
      "step": 7510
    },
    {
      "epoch": 2.436811406351264,
      "grad_norm": 0.5954488515853882,
      "learning_rate": 1.7922366517300594e-06,
      "loss": 0.1653,
      "step": 7520
    },
    {
      "epoch": 2.440051847051199,
      "grad_norm": 0.5870117545127869,
      "learning_rate": 1.772302133468381e-06,
      "loss": 0.1579,
      "step": 7530
    },
    {
      "epoch": 2.443292287751134,
      "grad_norm": 0.5913535356521606,
      "learning_rate": 1.7524683141618815e-06,
      "loss": 0.1653,
      "step": 7540
    },
    {
      "epoch": 2.446532728451069,
      "grad_norm": 0.630079984664917,
      "learning_rate": 1.7327354365570647e-06,
      "loss": 0.1632,
      "step": 7550
    },
    {
      "epoch": 2.4497731691510047,
      "grad_norm": 0.5680981874465942,
      "learning_rate": 1.713103742165002e-06,
      "loss": 0.1625,
      "step": 7560
    },
    {
      "epoch": 2.45301360985094,
      "grad_norm": 0.6326350569725037,
      "learning_rate": 1.6935734712583929e-06,
      "loss": 0.1698,
      "step": 7570
    },
    {
      "epoch": 2.456254050550875,
      "grad_norm": 0.5740662813186646,
      "learning_rate": 1.6741448628685985e-06,
      "loss": 0.1613,
      "step": 7580
    },
    {
      "epoch": 2.45949449125081,
      "grad_norm": 0.6102811694145203,
      "learning_rate": 1.6548181547827413e-06,
      "loss": 0.162,
      "step": 7590
    },
    {
      "epoch": 2.462734931950745,
      "grad_norm": 0.6032688021659851,
      "learning_rate": 1.6355935835407755e-06,
      "loss": 0.1664,
      "step": 7600
    },
    {
      "epoch": 2.4659753726506803,
      "grad_norm": 0.5765091776847839,
      "learning_rate": 1.6164713844326075e-06,
      "loss": 0.1581,
      "step": 7610
    },
    {
      "epoch": 2.4692158133506155,
      "grad_norm": 0.6408208012580872,
      "learning_rate": 1.5974517914952048e-06,
      "loss": 0.1638,
      "step": 7620
    },
    {
      "epoch": 2.472456254050551,
      "grad_norm": 0.6039566397666931,
      "learning_rate": 1.5785350375097418e-06,
      "loss": 0.1612,
      "step": 7630
    },
    {
      "epoch": 2.475696694750486,
      "grad_norm": 0.628781795501709,
      "learning_rate": 1.5597213539987344e-06,
      "loss": 0.162,
      "step": 7640
    },
    {
      "epoch": 2.4789371354504213,
      "grad_norm": 0.5742053985595703,
      "learning_rate": 1.5410109712232258e-06,
      "loss": 0.167,
      "step": 7650
    },
    {
      "epoch": 2.4821775761503564,
      "grad_norm": 0.5590866804122925,
      "learning_rate": 1.522404118179961e-06,
      "loss": 0.158,
      "step": 7660
    },
    {
      "epoch": 2.4854180168502915,
      "grad_norm": 0.5920097827911377,
      "learning_rate": 1.5039010225985683e-06,
      "loss": 0.1621,
      "step": 7670
    },
    {
      "epoch": 2.488658457550227,
      "grad_norm": 0.6175557971000671,
      "learning_rate": 1.4855019109388091e-06,
      "loss": 0.1609,
      "step": 7680
    },
    {
      "epoch": 2.491898898250162,
      "grad_norm": 0.5912847518920898,
      "learning_rate": 1.467207008387762e-06,
      "loss": 0.1567,
      "step": 7690
    },
    {
      "epoch": 2.4951393389500973,
      "grad_norm": 0.6249138712882996,
      "learning_rate": 1.4490165388571032e-06,
      "loss": 0.1632,
      "step": 7700
    },
    {
      "epoch": 2.4983797796500324,
      "grad_norm": 0.6321920156478882,
      "learning_rate": 1.4309307249803394e-06,
      "loss": 0.1624,
      "step": 7710
    },
    {
      "epoch": 2.5016202203499676,
      "grad_norm": 0.5669428706169128,
      "learning_rate": 1.4129497881101063e-06,
      "loss": 0.1614,
      "step": 7720
    },
    {
      "epoch": 2.5048606610499027,
      "grad_norm": 0.5820820331573486,
      "learning_rate": 1.3950739483154342e-06,
      "loss": 0.1624,
      "step": 7730
    },
    {
      "epoch": 2.508101101749838,
      "grad_norm": 0.6169790029525757,
      "learning_rate": 1.377303424379085e-06,
      "loss": 0.1642,
      "step": 7740
    },
    {
      "epoch": 2.511341542449773,
      "grad_norm": 0.6266772150993347,
      "learning_rate": 1.3596384337948433e-06,
      "loss": 0.1637,
      "step": 7750
    },
    {
      "epoch": 2.5145819831497085,
      "grad_norm": 0.6147197484970093,
      "learning_rate": 1.3420791927648792e-06,
      "loss": 0.1633,
      "step": 7760
    },
    {
      "epoch": 2.5178224238496436,
      "grad_norm": 0.5761263966560364,
      "learning_rate": 1.3246259161970808e-06,
      "loss": 0.1592,
      "step": 7770
    },
    {
      "epoch": 2.5210628645495787,
      "grad_norm": 0.5997585654258728,
      "learning_rate": 1.3072788177024454e-06,
      "loss": 0.1574,
      "step": 7780
    },
    {
      "epoch": 2.524303305249514,
      "grad_norm": 0.6142988204956055,
      "learning_rate": 1.2900381095924508e-06,
      "loss": 0.1596,
      "step": 7790
    },
    {
      "epoch": 2.527543745949449,
      "grad_norm": 0.6360519528388977,
      "learning_rate": 1.2729040028764627e-06,
      "loss": 0.1618,
      "step": 7800
    },
    {
      "epoch": 2.5307841866493845,
      "grad_norm": 0.6149975657463074,
      "learning_rate": 1.2558767072591438e-06,
      "loss": 0.163,
      "step": 7810
    },
    {
      "epoch": 2.5340246273493197,
      "grad_norm": 0.6006855964660645,
      "learning_rate": 1.238956431137901e-06,
      "loss": 0.1631,
      "step": 7820
    },
    {
      "epoch": 2.537265068049255,
      "grad_norm": 0.621221125125885,
      "learning_rate": 1.222143381600327e-06,
      "loss": 0.1626,
      "step": 7830
    },
    {
      "epoch": 2.54050550874919,
      "grad_norm": 0.6006029844284058,
      "learning_rate": 1.2054377644216576e-06,
      "loss": 0.1659,
      "step": 7840
    },
    {
      "epoch": 2.543745949449125,
      "grad_norm": 0.5786828398704529,
      "learning_rate": 1.1888397840622756e-06,
      "loss": 0.1602,
      "step": 7850
    },
    {
      "epoch": 2.54698639014906,
      "grad_norm": 0.5970851182937622,
      "learning_rate": 1.1723496436651838e-06,
      "loss": 0.1641,
      "step": 7860
    },
    {
      "epoch": 2.5502268308489953,
      "grad_norm": 0.5911303758621216,
      "learning_rate": 1.1559675450535345e-06,
      "loss": 0.1577,
      "step": 7870
    },
    {
      "epoch": 2.5534672715489304,
      "grad_norm": 0.6131963133811951,
      "learning_rate": 1.1396936887281506e-06,
      "loss": 0.1587,
      "step": 7880
    },
    {
      "epoch": 2.556707712248866,
      "grad_norm": 0.6302239298820496,
      "learning_rate": 1.123528273865082e-06,
      "loss": 0.1634,
      "step": 7890
    },
    {
      "epoch": 2.559948152948801,
      "grad_norm": 0.6209049820899963,
      "learning_rate": 1.1074714983131518e-06,
      "loss": 0.1623,
      "step": 7900
    },
    {
      "epoch": 2.563188593648736,
      "grad_norm": 0.6410764455795288,
      "learning_rate": 1.0915235585915563e-06,
      "loss": 0.1575,
      "step": 7910
    },
    {
      "epoch": 2.5664290343486713,
      "grad_norm": 0.5902949571609497,
      "learning_rate": 1.0756846498874386e-06,
      "loss": 0.1619,
      "step": 7920
    },
    {
      "epoch": 2.569669475048607,
      "grad_norm": 0.6085894703865051,
      "learning_rate": 1.0599549660535146e-06,
      "loss": 0.1627,
      "step": 7930
    },
    {
      "epoch": 2.572909915748542,
      "grad_norm": 0.5972374677658081,
      "learning_rate": 1.044334699605688e-06,
      "loss": 0.1581,
      "step": 7940
    },
    {
      "epoch": 2.576150356448477,
      "grad_norm": 0.6171351075172424,
      "learning_rate": 1.0288240417207084e-06,
      "loss": 0.1628,
      "step": 7950
    },
    {
      "epoch": 2.5793907971484122,
      "grad_norm": 0.6897320747375488,
      "learning_rate": 1.0134231822338225e-06,
      "loss": 0.1599,
      "step": 7960
    },
    {
      "epoch": 2.5826312378483474,
      "grad_norm": 0.6600574254989624,
      "learning_rate": 9.981323096364504e-07,
      "loss": 0.1591,
      "step": 7970
    },
    {
      "epoch": 2.5858716785482825,
      "grad_norm": 0.6364924907684326,
      "learning_rate": 9.829516110738779e-07,
      "loss": 0.1647,
      "step": 7980
    },
    {
      "epoch": 2.5891121192482176,
      "grad_norm": 0.6005523204803467,
      "learning_rate": 9.67881272342973e-07,
      "loss": 0.1654,
      "step": 7990
    },
    {
      "epoch": 2.5923525599481527,
      "grad_norm": 0.6278829574584961,
      "learning_rate": 9.529214778899109e-07,
      "loss": 0.1589,
      "step": 8000
    },
    {
      "epoch": 2.5955930006480883,
      "grad_norm": 0.6454229354858398,
      "learning_rate": 9.380724108078997e-07,
      "loss": 0.1622,
      "step": 8010
    },
    {
      "epoch": 2.5988334413480234,
      "grad_norm": 0.6531428098678589,
      "learning_rate": 9.23334252834972e-07,
      "loss": 0.1615,
      "step": 8020
    },
    {
      "epoch": 2.6020738820479585,
      "grad_norm": 0.6467439532279968,
      "learning_rate": 9.087071843517248e-07,
      "loss": 0.1615,
      "step": 8030
    },
    {
      "epoch": 2.6053143227478937,
      "grad_norm": 0.6310809850692749,
      "learning_rate": 8.941913843791394e-07,
      "loss": 0.1621,
      "step": 8040
    },
    {
      "epoch": 2.6085547634478288,
      "grad_norm": 0.5987969040870667,
      "learning_rate": 8.797870305763712e-07,
      "loss": 0.1669,
      "step": 8050
    },
    {
      "epoch": 2.6117952041477643,
      "grad_norm": 0.595566987991333,
      "learning_rate": 8.654942992385929e-07,
      "loss": 0.1637,
      "step": 8060
    },
    {
      "epoch": 2.6150356448476995,
      "grad_norm": 0.6209712028503418,
      "learning_rate": 8.51313365294818e-07,
      "loss": 0.1566,
      "step": 8070
    },
    {
      "epoch": 2.6182760855476346,
      "grad_norm": 0.6291006803512573,
      "learning_rate": 8.372444023057802e-07,
      "loss": 0.1582,
      "step": 8080
    },
    {
      "epoch": 2.6215165262475697,
      "grad_norm": 0.6080886721611023,
      "learning_rate": 8.232875824617892e-07,
      "loss": 0.1559,
      "step": 8090
    },
    {
      "epoch": 2.624756966947505,
      "grad_norm": 0.5870219469070435,
      "learning_rate": 8.094430765806382e-07,
      "loss": 0.1634,
      "step": 8100
    },
    {
      "epoch": 2.62799740764744,
      "grad_norm": 0.6187220215797424,
      "learning_rate": 7.957110541055024e-07,
      "loss": 0.163,
      "step": 8110
    },
    {
      "epoch": 2.631237848347375,
      "grad_norm": 0.6152703762054443,
      "learning_rate": 7.820916831028758e-07,
      "loss": 0.1644,
      "step": 8120
    },
    {
      "epoch": 2.63447828904731,
      "grad_norm": 0.5991233587265015,
      "learning_rate": 7.685851302605062e-07,
      "loss": 0.1636,
      "step": 8130
    },
    {
      "epoch": 2.6377187297472457,
      "grad_norm": 0.6252037882804871,
      "learning_rate": 7.551915608853588e-07,
      "loss": 0.1592,
      "step": 8140
    },
    {
      "epoch": 2.640959170447181,
      "grad_norm": 0.6103540062904358,
      "learning_rate": 7.41911138901592e-07,
      "loss": 0.1602,
      "step": 8150
    },
    {
      "epoch": 2.644199611147116,
      "grad_norm": 0.6074255108833313,
      "learning_rate": 7.287440268485479e-07,
      "loss": 0.1654,
      "step": 8160
    },
    {
      "epoch": 2.647440051847051,
      "grad_norm": 0.637297511100769,
      "learning_rate": 7.156903858787711e-07,
      "loss": 0.1577,
      "step": 8170
    },
    {
      "epoch": 2.6506804925469862,
      "grad_norm": 0.5995903611183167,
      "learning_rate": 7.027503757560239e-07,
      "loss": 0.1616,
      "step": 8180
    },
    {
      "epoch": 2.653920933246922,
      "grad_norm": 0.6600163578987122,
      "learning_rate": 6.899241548533497e-07,
      "loss": 0.1582,
      "step": 8190
    },
    {
      "epoch": 2.657161373946857,
      "grad_norm": 0.6119480729103088,
      "learning_rate": 6.77211880151114e-07,
      "loss": 0.1665,
      "step": 8200
    },
    {
      "epoch": 2.660401814646792,
      "grad_norm": 0.5992101430892944,
      "learning_rate": 6.646137072350967e-07,
      "loss": 0.1587,
      "step": 8210
    },
    {
      "epoch": 2.663642255346727,
      "grad_norm": 0.6972655653953552,
      "learning_rate": 6.5212979029458e-07,
      "loss": 0.1613,
      "step": 8220
    },
    {
      "epoch": 2.6668826960466623,
      "grad_norm": 0.716013491153717,
      "learning_rate": 6.397602821204718e-07,
      "loss": 0.16,
      "step": 8230
    },
    {
      "epoch": 2.6701231367465974,
      "grad_norm": 0.5907384753227234,
      "learning_rate": 6.275053341034187e-07,
      "loss": 0.1619,
      "step": 8240
    },
    {
      "epoch": 2.6733635774465325,
      "grad_norm": 0.5679281949996948,
      "learning_rate": 6.153650962319768e-07,
      "loss": 0.165,
      "step": 8250
    },
    {
      "epoch": 2.6766040181464676,
      "grad_norm": 0.6149739027023315,
      "learning_rate": 6.033397170907496e-07,
      "loss": 0.165,
      "step": 8260
    },
    {
      "epoch": 2.679844458846403,
      "grad_norm": 0.616990327835083,
      "learning_rate": 5.914293438585894e-07,
      "loss": 0.1578,
      "step": 8270
    },
    {
      "epoch": 2.6830848995463383,
      "grad_norm": 0.5920146107673645,
      "learning_rate": 5.79634122306787e-07,
      "loss": 0.1607,
      "step": 8280
    },
    {
      "epoch": 2.6863253402462735,
      "grad_norm": 0.6085196733474731,
      "learning_rate": 5.67954196797289e-07,
      "loss": 0.1642,
      "step": 8290
    },
    {
      "epoch": 2.6895657809462086,
      "grad_norm": 0.6078823804855347,
      "learning_rate": 5.563897102809334e-07,
      "loss": 0.1581,
      "step": 8300
    },
    {
      "epoch": 2.692806221646144,
      "grad_norm": 0.6765592098236084,
      "learning_rate": 5.449408042956971e-07,
      "loss": 0.164,
      "step": 8310
    },
    {
      "epoch": 2.6960466623460793,
      "grad_norm": 0.633089005947113,
      "learning_rate": 5.336076189649641e-07,
      "loss": 0.1631,
      "step": 8320
    },
    {
      "epoch": 2.6992871030460144,
      "grad_norm": 0.5943803191184998,
      "learning_rate": 5.223902929958113e-07,
      "loss": 0.1653,
      "step": 8330
    },
    {
      "epoch": 2.7025275437459495,
      "grad_norm": 0.6135101914405823,
      "learning_rate": 5.11288963677311e-07,
      "loss": 0.1593,
      "step": 8340
    },
    {
      "epoch": 2.7057679844458846,
      "grad_norm": 0.6370514631271362,
      "learning_rate": 5.003037668788479e-07,
      "loss": 0.1604,
      "step": 8350
    },
    {
      "epoch": 2.7090084251458197,
      "grad_norm": 0.6054797172546387,
      "learning_rate": 4.894348370484648e-07,
      "loss": 0.1592,
      "step": 8360
    },
    {
      "epoch": 2.712248865845755,
      "grad_norm": 0.6115302443504333,
      "learning_rate": 4.786823072112023e-07,
      "loss": 0.1584,
      "step": 8370
    },
    {
      "epoch": 2.71548930654569,
      "grad_norm": 0.6000931859016418,
      "learning_rate": 4.680463089674869e-07,
      "loss": 0.1618,
      "step": 8380
    },
    {
      "epoch": 2.7187297472456255,
      "grad_norm": 0.5907638669013977,
      "learning_rate": 4.5752697249150656e-07,
      "loss": 0.1584,
      "step": 8390
    },
    {
      "epoch": 2.7219701879455607,
      "grad_norm": 0.6245173215866089,
      "learning_rate": 4.4712442652962705e-07,
      "loss": 0.1646,
      "step": 8400
    },
    {
      "epoch": 2.725210628645496,
      "grad_norm": 0.6456656455993652,
      "learning_rate": 4.3683879839881204e-07,
      "loss": 0.1623,
      "step": 8410
    },
    {
      "epoch": 2.728451069345431,
      "grad_norm": 0.6109336614608765,
      "learning_rate": 4.266702139850676e-07,
      "loss": 0.1599,
      "step": 8420
    },
    {
      "epoch": 2.731691510045366,
      "grad_norm": 0.6063486337661743,
      "learning_rate": 4.166187977418934e-07,
      "loss": 0.1619,
      "step": 8430
    },
    {
      "epoch": 2.7349319507453016,
      "grad_norm": 0.6043286919593811,
      "learning_rate": 4.06684672688773e-07,
      "loss": 0.1656,
      "step": 8440
    },
    {
      "epoch": 2.7381723914452367,
      "grad_norm": 0.6053603887557983,
      "learning_rate": 3.968679604096548e-07,
      "loss": 0.1624,
      "step": 8450
    },
    {
      "epoch": 2.741412832145172,
      "grad_norm": 0.6160989999771118,
      "learning_rate": 3.8716878105147347e-07,
      "loss": 0.1593,
      "step": 8460
    },
    {
      "epoch": 2.744653272845107,
      "grad_norm": 0.6130458116531372,
      "learning_rate": 3.775872533226743e-07,
      "loss": 0.163,
      "step": 8470
    },
    {
      "epoch": 2.747893713545042,
      "grad_norm": 0.5923879742622375,
      "learning_rate": 3.681234944917644e-07,
      "loss": 0.1625,
      "step": 8480
    },
    {
      "epoch": 2.751134154244977,
      "grad_norm": 0.5867563486099243,
      "learning_rate": 3.5877762038587283e-07,
      "loss": 0.1577,
      "step": 8490
    },
    {
      "epoch": 2.7543745949449123,
      "grad_norm": 0.6155394315719604,
      "learning_rate": 3.4954974538933264e-07,
      "loss": 0.1618,
      "step": 8500
    },
    {
      "epoch": 2.7576150356448474,
      "grad_norm": 0.6299558877944946,
      "learning_rate": 3.4043998244229105e-07,
      "loss": 0.158,
      "step": 8510
    },
    {
      "epoch": 2.760855476344783,
      "grad_norm": 0.5918831825256348,
      "learning_rate": 3.3144844303931057e-07,
      "loss": 0.1626,
      "step": 8520
    },
    {
      "epoch": 2.764095917044718,
      "grad_norm": 0.641035795211792,
      "learning_rate": 3.225752372280222e-07,
      "loss": 0.1583,
      "step": 8530
    },
    {
      "epoch": 2.7673363577446533,
      "grad_norm": 0.6615086793899536,
      "learning_rate": 3.1382047360776325e-07,
      "loss": 0.1644,
      "step": 8540
    },
    {
      "epoch": 2.7705767984445884,
      "grad_norm": 0.6262204051017761,
      "learning_rate": 3.051842593282572e-07,
      "loss": 0.1588,
      "step": 8550
    },
    {
      "epoch": 2.7738172391445235,
      "grad_norm": 0.6701698303222656,
      "learning_rate": 2.9666670008829833e-07,
      "loss": 0.159,
      "step": 8560
    },
    {
      "epoch": 2.777057679844459,
      "grad_norm": 0.6074497699737549,
      "learning_rate": 2.882679001344624e-07,
      "loss": 0.1629,
      "step": 8570
    },
    {
      "epoch": 2.780298120544394,
      "grad_norm": 0.6364883184432983,
      "learning_rate": 2.799879622598256e-07,
      "loss": 0.1627,
      "step": 8580
    },
    {
      "epoch": 2.7835385612443293,
      "grad_norm": 0.6128090023994446,
      "learning_rate": 2.718269878027113e-07,
      "loss": 0.1642,
      "step": 8590
    },
    {
      "epoch": 2.7867790019442644,
      "grad_norm": 0.6271781921386719,
      "learning_rate": 2.6378507664544306e-07,
      "loss": 0.1629,
      "step": 8600
    },
    {
      "epoch": 2.7900194426441995,
      "grad_norm": 0.6506446003913879,
      "learning_rate": 2.5586232721313e-07,
      "loss": 0.1696,
      "step": 8610
    },
    {
      "epoch": 2.7932598833441347,
      "grad_norm": 0.6137887835502625,
      "learning_rate": 2.4805883647245896e-07,
      "loss": 0.1585,
      "step": 8620
    },
    {
      "epoch": 2.79650032404407,
      "grad_norm": 0.6612092852592468,
      "learning_rate": 2.4037469993050347e-07,
      "loss": 0.1592,
      "step": 8630
    },
    {
      "epoch": 2.7997407647440054,
      "grad_norm": 0.6140390634536743,
      "learning_rate": 2.3281001163356187e-07,
      "loss": 0.1639,
      "step": 8640
    },
    {
      "epoch": 2.8029812054439405,
      "grad_norm": 0.5835040807723999,
      "learning_rate": 2.2536486416600222e-07,
      "loss": 0.1549,
      "step": 8650
    },
    {
      "epoch": 2.8062216461438756,
      "grad_norm": 0.6698166131973267,
      "learning_rate": 2.1803934864913167e-07,
      "loss": 0.1635,
      "step": 8660
    },
    {
      "epoch": 2.8094620868438107,
      "grad_norm": 0.6182805299758911,
      "learning_rate": 2.1083355474007417e-07,
      "loss": 0.1627,
      "step": 8670
    },
    {
      "epoch": 2.812702527543746,
      "grad_norm": 0.6182749271392822,
      "learning_rate": 2.0374757063068573e-07,
      "loss": 0.1598,
      "step": 8680
    },
    {
      "epoch": 2.8159429682436814,
      "grad_norm": 0.5774921178817749,
      "learning_rate": 1.9678148304646317e-07,
      "loss": 0.1589,
      "step": 8690
    },
    {
      "epoch": 2.8191834089436165,
      "grad_norm": 0.5726456642150879,
      "learning_rate": 1.8993537724549038e-07,
      "loss": 0.1612,
      "step": 8700
    },
    {
      "epoch": 2.8224238496435516,
      "grad_norm": 0.6079289317131042,
      "learning_rate": 1.8320933701738709e-07,
      "loss": 0.1596,
      "step": 8710
    },
    {
      "epoch": 2.8256642903434868,
      "grad_norm": 0.5577754974365234,
      "learning_rate": 1.7660344468229508e-07,
      "loss": 0.1551,
      "step": 8720
    },
    {
      "epoch": 2.828904731043422,
      "grad_norm": 0.5872988700866699,
      "learning_rate": 1.7011778108985578e-07,
      "loss": 0.1593,
      "step": 8730
    },
    {
      "epoch": 2.832145171743357,
      "grad_norm": 0.6193456649780273,
      "learning_rate": 1.6375242561823545e-07,
      "loss": 0.1623,
      "step": 8740
    },
    {
      "epoch": 2.835385612443292,
      "grad_norm": 0.6499089598655701,
      "learning_rate": 1.5750745617314377e-07,
      "loss": 0.1638,
      "step": 8750
    },
    {
      "epoch": 2.8386260531432272,
      "grad_norm": 0.6274241209030151,
      "learning_rate": 1.5138294918688345e-07,
      "loss": 0.1605,
      "step": 8760
    },
    {
      "epoch": 2.841866493843163,
      "grad_norm": 0.6006873846054077,
      "learning_rate": 1.4537897961741653e-07,
      "loss": 0.1624,
      "step": 8770
    },
    {
      "epoch": 2.845106934543098,
      "grad_norm": 0.627119779586792,
      "learning_rate": 1.3949562094744295e-07,
      "loss": 0.1583,
      "step": 8780
    },
    {
      "epoch": 2.848347375243033,
      "grad_norm": 0.6071063876152039,
      "learning_rate": 1.3373294518350454e-07,
      "loss": 0.1624,
      "step": 8790
    },
    {
      "epoch": 2.851587815942968,
      "grad_norm": 0.6474395990371704,
      "learning_rate": 1.2809102285510356e-07,
      "loss": 0.1664,
      "step": 8800
    },
    {
      "epoch": 2.8548282566429033,
      "grad_norm": 0.719102680683136,
      "learning_rate": 1.2256992301383663e-07,
      "loss": 0.1654,
      "step": 8810
    },
    {
      "epoch": 2.858068697342839,
      "grad_norm": 0.6147641539573669,
      "learning_rate": 1.1716971323255444e-07,
      "loss": 0.1655,
      "step": 8820
    },
    {
      "epoch": 2.861309138042774,
      "grad_norm": 0.6404139399528503,
      "learning_rate": 1.1189045960452894e-07,
      "loss": 0.1637,
      "step": 8830
    },
    {
      "epoch": 2.864549578742709,
      "grad_norm": 0.6082090139389038,
      "learning_rate": 1.0673222674264849e-07,
      "loss": 0.167,
      "step": 8840
    },
    {
      "epoch": 2.8677900194426442,
      "grad_norm": 0.5927037000656128,
      "learning_rate": 1.016950777786263e-07,
      "loss": 0.1572,
      "step": 8850
    },
    {
      "epoch": 2.8710304601425793,
      "grad_norm": 0.5893467664718628,
      "learning_rate": 9.677907436222656e-08,
      "loss": 0.1613,
      "step": 8860
    },
    {
      "epoch": 2.8742709008425145,
      "grad_norm": 0.6549981236457825,
      "learning_rate": 9.198427666051279e-08,
      "loss": 0.1626,
      "step": 8870
    },
    {
      "epoch": 2.8775113415424496,
      "grad_norm": 0.588086724281311,
      "learning_rate": 8.731074335710742e-08,
      "loss": 0.1622,
      "step": 8880
    },
    {
      "epoch": 2.8807517822423847,
      "grad_norm": 0.5953313708305359,
      "learning_rate": 8.275853165147452e-08,
      "loss": 0.1667,
      "step": 8890
    },
    {
      "epoch": 2.8839922229423203,
      "grad_norm": 0.664451003074646,
      "learning_rate": 7.832769725822364e-08,
      "loss": 0.1672,
      "step": 8900
    },
    {
      "epoch": 2.8872326636422554,
      "grad_norm": 0.6038045883178711,
      "learning_rate": 7.401829440642272e-08,
      "loss": 0.1621,
      "step": 8910
    },
    {
      "epoch": 2.8904731043421905,
      "grad_norm": 0.608932375907898,
      "learning_rate": 6.983037583893848e-08,
      "loss": 0.1653,
      "step": 8920
    },
    {
      "epoch": 2.8937135450421256,
      "grad_norm": 0.5602173805236816,
      "learning_rate": 6.576399281178813e-08,
      "loss": 0.1594,
      "step": 8930
    },
    {
      "epoch": 2.8969539857420608,
      "grad_norm": 0.6284700036048889,
      "learning_rate": 6.181919509351209e-08,
      "loss": 0.1662,
      "step": 8940
    },
    {
      "epoch": 2.9001944264419963,
      "grad_norm": 0.6069345474243164,
      "learning_rate": 5.799603096456774e-08,
      "loss": 0.1539,
      "step": 8950
    },
    {
      "epoch": 2.9034348671419314,
      "grad_norm": 0.601305365562439,
      "learning_rate": 5.429454721673555e-08,
      "loss": 0.1589,
      "step": 8960
    },
    {
      "epoch": 2.9066753078418666,
      "grad_norm": 0.5839999318122864,
      "learning_rate": 5.0714789152547236e-08,
      "loss": 0.1591,
      "step": 8970
    },
    {
      "epoch": 2.9099157485418017,
      "grad_norm": 0.6398387551307678,
      "learning_rate": 4.725680058473292e-08,
      "loss": 0.1615,
      "step": 8980
    },
    {
      "epoch": 2.913156189241737,
      "grad_norm": 0.5685884356498718,
      "learning_rate": 4.392062383568041e-08,
      "loss": 0.1611,
      "step": 8990
    },
    {
      "epoch": 2.916396629941672,
      "grad_norm": 0.6198070049285889,
      "learning_rate": 4.0706299736923415e-08,
      "loss": 0.1622,
      "step": 9000
    },
    {
      "epoch": 2.919637070641607,
      "grad_norm": 0.6059020161628723,
      "learning_rate": 3.76138676286375e-08,
      "loss": 0.1609,
      "step": 9010
    },
    {
      "epoch": 2.9228775113415426,
      "grad_norm": 0.6055730581283569,
      "learning_rate": 3.4643365359158244e-08,
      "loss": 0.1595,
      "step": 9020
    },
    {
      "epoch": 2.9261179520414777,
      "grad_norm": 0.659947395324707,
      "learning_rate": 3.179482928452382e-08,
      "loss": 0.1601,
      "step": 9030
    },
    {
      "epoch": 2.929358392741413,
      "grad_norm": 0.5865605473518372,
      "learning_rate": 2.9068294268020935e-08,
      "loss": 0.1636,
      "step": 9040
    },
    {
      "epoch": 2.932598833441348,
      "grad_norm": 0.6079728007316589,
      "learning_rate": 2.646379367976626e-08,
      "loss": 0.1652,
      "step": 9050
    },
    {
      "epoch": 2.935839274141283,
      "grad_norm": 0.627241849899292,
      "learning_rate": 2.3981359396292315e-08,
      "loss": 0.1619,
      "step": 9060
    },
    {
      "epoch": 2.9390797148412187,
      "grad_norm": 0.6240661144256592,
      "learning_rate": 2.1621021800160012e-08,
      "loss": 0.1587,
      "step": 9070
    },
    {
      "epoch": 2.942320155541154,
      "grad_norm": 0.5925166606903076,
      "learning_rate": 1.938280977959006e-08,
      "loss": 0.1578,
      "step": 9080
    },
    {
      "epoch": 2.945560596241089,
      "grad_norm": 0.5958002805709839,
      "learning_rate": 1.7266750728101023e-08,
      "loss": 0.1567,
      "step": 9090
    },
    {
      "epoch": 2.948801036941024,
      "grad_norm": 0.5781446695327759,
      "learning_rate": 1.5272870544182917e-08,
      "loss": 0.1611,
      "step": 9100
    },
    {
      "epoch": 2.952041477640959,
      "grad_norm": 0.6465507745742798,
      "learning_rate": 1.3401193630971921e-08,
      "loss": 0.159,
      "step": 9110
    },
    {
      "epoch": 2.9552819183408943,
      "grad_norm": 0.6383660435676575,
      "learning_rate": 1.1651742895960606e-08,
      "loss": 0.1594,
      "step": 9120
    },
    {
      "epoch": 2.9585223590408294,
      "grad_norm": 0.6105998754501343,
      "learning_rate": 1.0024539750709273e-08,
      "loss": 0.1545,
      "step": 9130
    },
    {
      "epoch": 2.9617627997407645,
      "grad_norm": 0.6656136512756348,
      "learning_rate": 8.519604110590608e-09,
      "loss": 0.1564,
      "step": 9140
    },
    {
      "epoch": 2.9650032404407,
      "grad_norm": 0.6093752980232239,
      "learning_rate": 7.136954394538764e-09,
      "loss": 0.1622,
      "step": 9150
    },
    {
      "epoch": 2.968243681140635,
      "grad_norm": 0.6296285390853882,
      "learning_rate": 5.876607524833988e-09,
      "loss": 0.1647,
      "step": 9160
    },
    {
      "epoch": 2.9714841218405703,
      "grad_norm": 0.6455819606781006,
      "learning_rate": 4.738578926882787e-09,
      "loss": 0.1607,
      "step": 9170
    },
    {
      "epoch": 2.9747245625405054,
      "grad_norm": 0.5850232839584351,
      "learning_rate": 3.722882529042515e-09,
      "loss": 0.1664,
      "step": 9180
    },
    {
      "epoch": 2.9779650032404406,
      "grad_norm": 0.5963045358657837,
      "learning_rate": 2.829530762439303e-09,
      "loss": 0.1596,
      "step": 9190
    },
    {
      "epoch": 2.981205443940376,
      "grad_norm": 0.6031000018119812,
      "learning_rate": 2.0585345608237217e-09,
      "loss": 0.1605,
      "step": 9200
    },
    {
      "epoch": 2.9844458846403112,
      "grad_norm": 0.6767995953559875,
      "learning_rate": 1.4099033604331181e-09,
      "loss": 0.1598,
      "step": 9210
    },
    {
      "epoch": 2.9876863253402464,
      "grad_norm": 0.5986335873603821,
      "learning_rate": 8.836450998783719e-10,
      "loss": 0.1635,
      "step": 9220
    },
    {
      "epoch": 2.9909267660401815,
      "grad_norm": 0.5985670685768127,
      "learning_rate": 4.797662200428654e-10,
      "loss": 0.1621,
      "step": 9230
    },
    {
      "epoch": 2.9941672067401166,
      "grad_norm": 0.6140903234481812,
      "learning_rate": 1.982716640092086e-10,
      "loss": 0.1589,
      "step": 9240
    },
    {
      "epoch": 2.9974076474400517,
      "grad_norm": 0.6781088709831238,
      "learning_rate": 3.916487699484606e-11,
      "loss": 0.1629,
      "step": 9250
    },
    {
      "epoch": 3.0,
      "step": 9258,
      "total_flos": 1.5663703576629215e+19,
      "train_loss": 0.1868666987821901,
      "train_runtime": 47416.1707,
      "train_samples_per_second": 24.991,
      "train_steps_per_second": 0.195
    }
  ],
  "logging_steps": 10,
  "max_steps": 9258,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000.0,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.5663703576629215e+19,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
